{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1U5vU6MN7DGi4_zDWZVzn94MPfb9MMWWq",
      "authorship_tag": "ABX9TyPjrUnbbYFlDz2Z7nPnI3kw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/encoras/Artificial-Intelligence-Group/blob/master/Feature_selection_Task_classifier_adult.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from  sklearn import datasets\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import accuracy_score, precision_score\n",
        "from sklearn.metrics import recall_score, f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, classification_report\n",
        "from sklearn import svm\n",
        "from numpy.random import seed\n"
      ],
      "metadata": {
        "id": "gxqvnorGIRr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RAND=22310 # should be your student code abcd**"
      ],
      "metadata": {
        "id": "fDMi9snGp0zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RAND=1234 # should be your student code abcd\n",
        "seed(RAND)"
      ],
      "metadata": {
        "id": "BFA9qlmypF2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from https://drive.google.com/file/d/1-jrwZmZ3kqH-3JbckqbxEsr7EjW27IDJ/view?usp=sharing copy file archive.zip to your folder."
      ],
      "metadata": {
        "id": "Z2daOMRPcl97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/archive.zip')"
      ],
      "metadata": {
        "id": "GCg5qLcsmMkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df.head()"
      ],
      "metadata": {
        "id": "dNWO_0cnmuGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**About the Dataset**\n",
        "```*Age: Describes the age of individuals. Continuous.\n",
        "*Workclass*: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
        "*fnlwgt*: Continuous.\n",
        "*education*: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
        "*education-num*: Number of years spent in education. Continuous.\n",
        "*marital-status*: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
        "*occupation*: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
        "*relationship*: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
        "*race*: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
        "*sex*: Female, Male.\n",
        "*capital-gain*: Continuous.\n",
        "*capital-loss*: Continuous.\n",
        "*hours-per-week*: Continuous.\n",
        "*native-country*: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\n",
        "*salary*: >50K,<=50K  ---- CLASSIFICATION Target\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "JHRJKM6_m692"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the columns workclass, occupation, and native.country contains null values. There can be many ways to impute missing values, but right now, for the sake of simplicity we would impute them using mode!\n",
        "\n"
      ],
      "metadata": {
        "id": "Ela4z68crHTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in ['workclass', 'occupation', 'native.country']:\n",
        "    df[col].fillna(df[col].mode()[0], inplace=True)"
      ],
      "metadata": {
        "id": "bW_iMWP7rFzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data preparation for a model implementation"
      ],
      "metadata": {
        "id": "xYs5sZHir9BY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "categorical = ['workclass','education', 'marital.status', 'occupation', 'relationship',\n",
        "               'race', 'sex','native.country','income']\n",
        "label_encoder = LabelEncoder()\n",
        "for col in categorical:\n",
        "    label_encoder.fit(df[col])\n",
        "    df[col] = label_encoder.transform(df[col])\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = df[['workclass','education', 'marital.status', 'occupation', 'relationship',\n",
        "               'race', 'sex','native.country', 'age', 'hours.per.week']]\n",
        "y = df['income']\n",
        "\n",
        "feature_name = ['workclass','education', 'marital.status', 'occupation', 'relationship',\n",
        "               'race', 'sex','native.country', 'age', 'hours.per.week']"
      ],
      "metadata": {
        "id": "pPmTNi_VsB7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#let's split data and do input feature transform."
      ],
      "metadata": {
        "id": "cdtYGt-8xzy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_tr, X_te, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=RAND, shuffle=True, stratify=y)"
      ],
      "metadata": {
        "id": "1MDElFLXIp1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_tr)\n",
        "X_train=scaler.transform(X_tr)\n",
        "X_test=scaler.transform(X_te)"
      ],
      "metadata": {
        "id": "tUJuxXCYRG_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's implement the baseline model. With THE BEST parameters from the assignment 2 and all features from a dataset."
      ],
      "metadata": {
        "id": "wCDXEgoBzchs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The task 1.**\n",
        "Depending on the last digit of your student Internal code (abcde) take an \"optimal\" specific *parameter* from the assignment 2.\n",
        "The RAND variable is your student ID numbers RAND=\"bcde\" at a top of the code.\n",
        "\n",
        "0. DecisionTreeClassifier(criterion='entropy', random_state=RAND, min_samples_split = `???`)\n",
        "1. DecisionTreeClassifier(criterion='gini', random_state=RAND, max_depth = `???`)\n",
        "2. KNeighborsClassifier(n_neighbors=`???`, p=2)\n",
        "3. KNeighborsClassifier(n_neighbors='???', p=1)\n",
        "4. svm. SVC(random_state=RAND, kernel='linear', C=`???`)\n",
        "5. svm.SVC(random_state=RAND, kernel='rbf', gamma=0.07, C=`???`)\n",
        "6. svm.SVC(random_state=RAND,kernel='poly', degree=3, C=`???`)\n",
        "7. svm.LinearSVC(random_state=RAND,C=`???`)\n",
        "8. MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(`???`,), random_state=RAND)\n",
        "9. MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(`???`,5), random_state=RAND)"
      ],
      "metadata": {
        "id": "ndb9y7x9SZni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = --to code--\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "scores_baseline=metrics.accuracy_score(y_test,y_pred)\n",
        "print(\"Baseline accuracy = \", scores_baseline)\n"
      ],
      "metadata": {
        "id": "SBWORuRwSoxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Confusion matrix\n",
        "# -- to code --\n"
      ],
      "metadata": {
        "id": "aITCslgDJnXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Baseline metrics:\")\n",
        "print(\"- Accuracy  = %.3f\" % accuracy_score(y_test, y_pred))\n",
        "print(\"- ROC AUC   = %.3f\" % roc_auc_score(y_test, y_pred))\n",
        "# compute the classification report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "RNFmhLvCLH4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------------------------------------------------------------------\n",
        "**Now, let's build your model with feature selection.**\n",
        "-----------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "44TxuLk9NAFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RAND=123 ## Student ID abcde\n",
        "!pip install boruta"
      ],
      "metadata": {
        "id": "wg_Gt6RNsfy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The task 2. features selection by chi2  or f_classif.\n",
        "\n",
        "2.1 If your student number last digit >5 then to use \"chi2\", **else**  \"f_classif\" .\n",
        "\n",
        "\n",
        "2.2 Find the best number of feature by changing k"
      ],
      "metadata": {
        "id": "W4TZqy_W887M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
        "\n",
        "#features selection by chi2  or f_classif\n",
        "#if your student number last digit >5 then to use \"chi2\", else  f_classif\n",
        "#Find the best number of feature by changing k\n",
        "\n",
        "chi2_features = SelectKBest(--code-- , k= --code)\n",
        "#train\n",
        "chi2_features.fit(abs(X_train), y_train)\n",
        "\n",
        "print(chi2_features.get_support())\n",
        "#Apply feature selection and return transformed data\n",
        "X_train_filtered = --code--\n",
        "X_test_filtered = --code --\n",
        "\n",
        "#check your model accuracy with reduced number of features\n",
        "model.fit(X_train_filtered, y_train)\n",
        "y_pred = model.predict(X_test_filtered)\n",
        "score_filtered_chi2=metrics.accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(\"Accuracy_K_Best = \", score_filtered_chi2)"
      ],
      "metadata": {
        "id": "-zdRLbEErEcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The task 3. features selection by SequentialFeatureSelector.\n",
        "\n",
        "3.1 If your student number last digit >5 then to use \"backward\", else \"forward\" .\n",
        "\n",
        "3.2 Find the best number of feature by changing n_features_to_select"
      ],
      "metadata": {
        "id": "G7Q_5SZ6-nzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SequentialFeatureSelector\n",
        "\n",
        "sfs = SequentialFeatureSelector(GaussianNB(), direction='backward', n_features_to_select=4)\n",
        "#train\n",
        "sfs.fit(X_train, y_train)\n",
        "#print selected features\n",
        "print(sfs.get_support())\n",
        "\n",
        "#Apply feature selection and return transformed data\n",
        "X_train_filtered = -- to code\n",
        "X_test_filtered = -- to code\n",
        "#train your model\n",
        "model.fit(X_train_filtered, y_train)\n",
        "y_pred = model.predict(X_test_filtered)\n",
        "score_filtered_sfs=metrics.accuracy_score(y_test,y_pred)\n",
        "print(\"Accuracy_sfs = \", score_filtered_sfs)"
      ],
      "metadata": {
        "id": "vmU8uclUsiXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4. Feature selection by Boruta wraper.\n",
        "4.1 If your student number last digit >5 then to use \"rfc\", else \"etc\" .\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HcGA-OCKAY1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Install Boruta for first time\n",
        "#!pip install boruta\n",
        "from boruta import BorutaPy\n",
        "\n",
        "np.int = np.int32\n",
        "np.float = np.float64\n",
        "np.bool = np.bool_\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc = RandomForestClassifier(random_state=RAND)\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "etc = ExtraTreesClassifier(random_state=RAND)\n",
        "\n",
        "# define Boruta feature selection method by ensamble classifier:  rfc, etc\n",
        "\n",
        "feat_selector = BorutaPy(--code--, n_estimators='auto', verbose=1, random_state=RAND, max_iter=30) #, max_iter=10\n",
        "\n",
        "# find all relevant features\n",
        "feat_selector.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# check selected features\n",
        "print(feat_selector.support_)  #Should we accept the feature\n",
        "\n",
        "# check ranking of features\n",
        "print(feat_selector.ranking_) #Rank 1 is the best"
      ],
      "metadata": {
        "id": "4JVh7LeTWxXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Review the features\n",
        "\"\"\"\n",
        "# zip feature names, ranks, and decisions\n",
        "feature_ranks = list(zip(feature_name,\n",
        "                         feat_selector.ranking_,\n",
        "                         feat_selector.support_))\n",
        "\n",
        "# print the results\n",
        "new_names=[]\n",
        "for feat in feature_ranks:\n",
        "    print('Feature: {:<30} Rank: {},  Keep: {}'.format(feat[0], feat[1], feat[2]))\n",
        "    if feat[2]:\n",
        "     new_names.append(feat[0])"
      ],
      "metadata": {
        "id": "KfMqLvWMkubL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# what features ar most important for a classification task?\n",
        "new_names"
      ],
      "metadata": {
        "id": "7rKejoxCfg3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply feature selection and return transformed data\n",
        "X_train_filtered = -- code --\n",
        "X_test_filtered = --code --"
      ],
      "metadata": {
        "id": "r-Yj1yReTkXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train model\n",
        "model.fit(X_train_filtered, y_train)\n",
        "y_pred = model.predict(X_test_filtered)\n",
        "score_filtered_B=metrics.accuracy_score(y_test,y_pred)\n",
        "print(\"Boruta accuracy = \", score_filtered_B)"
      ],
      "metadata": {
        "id": "vBMHP1s4eS-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot confusion matrixes of a classifier with Boruta selected features\n",
        "#-- to code--\n",
        "\n"
      ],
      "metadata": {
        "id": "wYRlfvxvc8NU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Boruta accuracy metrics:\")\n",
        "print(\"- Accuracy  = %.3f\" % accuracy_score(y_test, y_pred))\n",
        "print(\"- ROC AUC   = %.3f\" % roc_auc_score(y_test, y_pred))\n",
        "# compute the classification report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "E_BFs5glj1LW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 5. Compare Base line classifier accuracy to classifiers with reduced features and make an conclusion of improvement. What features were most oftten selected?"
      ],
      "metadata": {
        "id": "FuaE26FfCJ3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "-- to code --"
      ],
      "metadata": {
        "id": "aNavYbBOC4b0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bonus**: train a decision tree on reduced features. From the decision tree graph Explain - what you need \"to do\" in order to get into class \">50K\"."
      ],
      "metadata": {
        "id": "LvWzvXXIDKPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn import tree\n",
        "dtc_model = DecisionTreeClassifier(max_depth=3, random_state=123)\n",
        "dtc_model.fit(X_train_filtered, y_train)\n",
        "fig = plt.figure(figsize=(25,20))\n",
        "_ = tree.plot_tree(dtc_model,\n",
        "                   feature_names=new_names,\n",
        "                   class_names=['<=50K' , '>50K'],\n",
        "                   filled=True)"
      ],
      "metadata": {
        "id": "Z4ehWAUsdn29"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}