{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/encoras/Artificial-Intelligence-Group/blob/master/train_vitTiny16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "08c1a984-e075-45c4-b22c-74bd9525ebc1",
      "metadata": {
        "id": "08c1a984-e075-45c4-b22c-74bd9525ebc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec7f150d-ab99-425f-8049-2af4e9f1a20e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/634.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m430.1/634.9 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m634.9/634.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -qq install keras-cv\n",
        "\n",
        "!pip -qq install pycocotools\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5BQW6UIkI5bW"
      },
      "id": "5BQW6UIkI5bW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gur74IifI68x",
        "outputId": "bdbda89e-ce2d-407d-ecfe-77375c12f256"
      },
      "id": "Gur74IifI68x",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/data\n",
        "#!gdown https://drive.google.com/uc?id=1_IAWexEWpH-ly_JaA5EGfZDp-_3flkN1\n",
        "!unzip -q /content/drive/MyDrive/Audiodata/ALL_images.zip -d /content/ALL_images/\n",
        "#!mv \"/content/data/Acted Emotional Speech Dynamic Database/\" /content/data/aesdd/"
      ],
      "metadata": {
        "id": "dKi3oJV4Jiqw"
      },
      "id": "dKi3oJV4Jiqw",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af682273-999a-4ec5-bf27-84b7066b09c4",
      "metadata": {
        "id": "af682273-999a-4ec5-bf27-84b7066b09c4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e6a8a32e-6fc2-4915-b85d-faa55bb539f4",
      "metadata": {
        "id": "e6a8a32e-6fc2-4915-b85d-faa55bb539f4",
        "outputId": "8fe0875b-24fc-45ac-8c07-520f330ef82b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You do not have Waymo Open Dataset installed, so KerasCV Waymo metrics are not available.\n",
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "\n",
        "\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Conv2D, SpatialDropout2D\n",
        "from keras.layers import MaxPooling2D, BatchNormalization, AveragePooling2D, GlobalAveragePooling2D\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "import sys\n",
        "from keras.layers import Layer, Activation, LeakyReLU\n",
        "import shutil\n",
        "\n",
        "import keras_cv as kcv\n",
        "from keras_cv.models import ViTTiny16\n",
        "from keras_cv.layers import preprocessing\n",
        "\n",
        "#import wandb\n",
        "#from wandb.keras import WandbMetricsLogger\n",
        "#from wandb.keras import WandbEvalCallback\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "if not sys.warnoptions:\n",
        "    import warnings\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "fd70d298-5a56-4d65-b63a-2e20df068e6d",
      "metadata": {
        "id": "fd70d298-5a56-4d65-b63a-2e20df068e6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50b6932b-a9af-4ad5-8740-e611d70e1d1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "print(tf.config.list_physical_devices())\n",
        "tf.compat.v1.set_random_seed(1)\n",
        "\n",
        "from keras import backend as K\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    #y_pred = np.argmax(y_pred, axis=1)\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "def loss_f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 1-2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "def dice_crossentropy(y_truth, y_pred):\n",
        "    # Obtain Soft DSC\n",
        "    dice = loss_f1_m(y_truth, y_pred)\n",
        "    # Obtain Crossentropy\n",
        "    crossentropy = K.categorical_crossentropy(y_truth, y_pred)\n",
        "    crossentropy = K.mean(crossentropy)\n",
        "    # Return sum\n",
        "    return dice + crossentropy\n",
        "\n",
        "def define_model(start_kernels=16, input_shape=(128, 128, 1), pretrained_weights=None):\n",
        "    from tensorflow.keras import regularizers\n",
        "    # https://keras.io/api/layers/convolution_layers/convolution1d/\n",
        "    model = tf.keras.Sequential([\n",
        "        ############ 1\n",
        "        Conv2D(start_kernels, kernel_size=5, padding='same', kernel_initializer='he_normal', use_bias=False,\n",
        "               input_shape=input_shape),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        SpatialDropout2D(0.015),\n",
        "        MaxPooling2D(pool_size=2),  # <---1\n",
        "        ############ 2\n",
        "        Conv2D(start_kernels * 2, kernel_size=5, strides=1, padding='same', kernel_initializer='he_normal',\n",
        "               use_bias=False, kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4)),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        SpatialDropout2D(0.015),\n",
        "        MaxPooling2D(pool_size=2),  # <---2\n",
        "        ############ 3\n",
        "        Conv2D(start_kernels * 4, kernel_size=3, strides=1, padding='same', kernel_initializer='he_normal',\n",
        "               use_bias=False,kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4)),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        SpatialDropout2D(0.015),\n",
        "        MaxPooling2D(pool_size=2),  # <---3\n",
        "        ############# 4\n",
        "        #Conv2D(start_kernels * 8, kernel_size=3, strides=2, padding='same', kernel_initializer='he_normal',\n",
        "        #      use_bias=False),\n",
        "        #BatchNormalization(),\n",
        "        #LeakyReLU(alpha=0.1),\n",
        "        #MaxPooling2D(pool_size=2),  # <---4\n",
        "\n",
        "        ############# 5\n",
        "        #Conv2D(start_kernels * 8, kernel_size=3, strides=2, padding='same', kernel_initializer='he_normal',\n",
        "        #       use_bias=False),\n",
        "        #BatchNormalization(),\n",
        "        #LeakyReLU(alpha=0.1),\n",
        "        #MaxPooling2D(pool_size=2),  # <---5\n",
        "\n",
        "        ############# fully connected\n",
        "        Flatten(), #GlobalAveragePooling2D(),\n",
        "        #Dense(512),\n",
        "        #LeakyReLU(alpha=0.1),\n",
        "        #Dense(64,\n",
        "        #        kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
        "        #        bias_regularizer=regularizers.l2(1e-4),\n",
        "        #        activity_regularizer=regularizers.l2(1e-5)),\n",
        "        #LeakyReLU(alpha=0.1),\n",
        "        Dense(32,\n",
        "                kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
        "                bias_regularizer=regularizers.l2(1e-4),\n",
        "                activity_regularizer=regularizers.l2(1e-5)),\n",
        "        \n",
        "        LeakyReLU(alpha=0.1),\n",
        "        Dropout(0.02),\n",
        "        Dense(7, activation='softmax',\n",
        "                kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
        "                bias_regularizer=regularizers.l2(1e-4),\n",
        "                activity_regularizer=regularizers.l2(1e-5))\n",
        "    ])\n",
        "\n",
        "    # model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n",
        "    model.compile(loss=dice_crossentropy, optimizer=Adam(lr=0.1e-3),\n",
        "                  metrics=['categorical_accuracy', f1_m])\n",
        "\n",
        "    #if pretrained_weights:\n",
        "        #model.load_weights(pretrained_weights)\n",
        "\n",
        "    return model\n",
        "\n",
        "def get_model():\n",
        "    inputs = tf.keras.layers.Input(shape=(224, 224, 3))\n",
        "\n",
        "\n",
        "    vit = ViTTiny16(\n",
        "        include_rescaling=False,\n",
        "        include_top=False,\n",
        "        name=\"ViTTiny16\",\n",
        "        weights=\"imagenet\",\n",
        "        input_tensor=inputs,\n",
        "        pooling=\"token_pooling\",\n",
        "        activation=tf.keras.activations.gelu,\n",
        "    )    \n",
        "    vit.trainable = True\n",
        "\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(7, activation=\"softmax\")(vit.output)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "84099b01-161f-45c4-bc0c-169d65f4b1dd",
      "metadata": {
        "id": "84099b01-161f-45c4-bc0c-169d65f4b1dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90e0e230-fe53-4be5-959a-7b390711203c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['angry000' 'disgust2' 'fear3333' 'happy444' 'neutral5' 'sad66666'\n",
            " 'surprise']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "##\n",
        "IMG_HEIGHT, IMG_WIDTH = (224, 224)\n",
        "batch_size=15\n",
        "epochs = 40\n",
        "##\n",
        "\n",
        "\n",
        "\n",
        "img_folder = Path(\"/content/ALL_images/\").expanduser()\n",
        "\n",
        "image_filenames = glob.glob(str(img_folder / '**/*.png'))\n",
        "id=[]\n",
        "for i in range(len(image_filenames)):\n",
        "        #print(image_filenames[i][11:19])\n",
        "        id.append((image_filenames[i][20:28]))\n",
        "\n",
        "data = {'id':image_filenames,'label':id}\n",
        "df_large = pd.DataFrame(data)\n",
        "all_labels = np.unique(id)\n",
        "print(all_labels)\n",
        "\n",
        "#https://stackoverflow.com/questions/60460064/validation-set-only-gets-images-from-one-class-when-using-keras-imagedatagenerat\n",
        "from sklearn.utils import shuffle \n",
        "df_large = shuffle(df_large, random_state=0)\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint \n",
        "mcp_save = ModelCheckpoint('/content/drive/MyDrive/Audiodata/grayTT_wts.hdf5', save_best_only=True, verbose=1, monitor='val_categorical_accuracy', mode='max') \n",
        "callbacks = [mcp_save]#,\n",
        "\n",
        "def classification_report_csv(report,i):\n",
        "\n",
        "    dataframe = pd.DataFrame(report).transpose()\n",
        "    dataframe.to_csv('/content/drive/MyDrive/Audiodata/Rez_ViTTiny16/k_classification_report_'+str(i)+'_.csv', index = False)\n",
        "\n",
        "## main loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0a3bbe61-84f3-4034-8c15-ace1a788dc50",
      "metadata": {
        "id": "0a3bbe61-84f3-4034-8c15-ace1a788dc50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "271e5e69-98d2-4f74-9a62-d677bd46246c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Kfold 1\n",
            "Train shape: (3627, 2)\n",
            "Test shape: (907, 2)\n",
            "Found 3627 validated image filenames belonging to 7 classes.\n",
            "Found 725 validated image filenames belonging to 7 classes.\n",
            "Found 907 validated image filenames belonging to 7 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/preprocessing/image.py:1444: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " rescaling_2 (Rescaling)     (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " patching_and_embedding_4 (P  (None, 197, 192)         185664    \n",
            " atchingAndEmbedding)                                            \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 197, 192)          0         \n",
            "                                                                 \n",
            " transformer_encoder_48 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_49 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_50 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_51 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_52 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_53 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_54 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_55 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_56 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_57 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_58 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_59 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " layer_normalization_124 (La  (None, 197, 192)         384       \n",
            " yerNormalization)                                               \n",
            "                                                                 \n",
            " lambda_4 (Lambda)           (None, 192)               0         \n",
            "                                                                 \n",
            " dense_124 (Dense)           (None, 7)                 1351      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,525,767\n",
            "Trainable params: 5,525,767\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-c745ba16ed14>:98: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  y_pred = model.predict_generator(test_generator, STEP_SIZE_TEST, verbose=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "907/907 [==============================] - 22s 22ms/step\n",
            "(907,)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.80      0.83       137\n",
            "           1       0.86      0.78      0.82       130\n",
            "           2       0.78      0.76      0.77       134\n",
            "           3       0.82      0.74      0.78       128\n",
            "           4       0.81      0.87      0.84       118\n",
            "           5       0.71      0.87      0.78       122\n",
            "           6       0.85      0.86      0.85       138\n",
            "\n",
            "    accuracy                           0.81       907\n",
            "   macro avg       0.81      0.81      0.81       907\n",
            "weighted avg       0.81      0.81      0.81       907\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Kfold 2\n",
            "Train shape: (3627, 2)\n",
            "Test shape: (907, 2)\n",
            "Found 3627 validated image filenames belonging to 7 classes.\n",
            "Found 725 validated image filenames belonging to 7 classes.\n",
            "Found 907 validated image filenames belonging to 7 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/preprocessing/image.py:1444: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " rescaling_2 (Rescaling)     (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " patching_and_embedding_5 (P  (None, 197, 192)         185664    \n",
            " atchingAndEmbedding)                                            \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 197, 192)          0         \n",
            "                                                                 \n",
            " transformer_encoder_60 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_61 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_62 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_63 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_64 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_65 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_66 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_67 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_68 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_69 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_70 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_71 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " layer_normalization_149 (La  (None, 197, 192)         384       \n",
            " yerNormalization)                                               \n",
            "                                                                 \n",
            " lambda_5 (Lambda)           (None, 192)               0         \n",
            "                                                                 \n",
            " dense_149 (Dense)           (None, 7)                 1351      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,525,767\n",
            "Trainable params: 5,525,767\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-c745ba16ed14>:86: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(generator=train_generator,\n",
            "/usr/local/lib/python3.9/dist-packages/keras/preprocessing/image.py:1861: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/keras/preprocessing/image.py:1884: UserWarning: This ImageDataGenerator specifies `zca_whitening`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 1.6175 - categorical_accuracy: 0.6260 - f1_m: 0.6086\n",
            "Epoch 1: val_categorical_accuracy improved from -inf to 0.76828, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 117s 312ms/step - loss: 1.6175 - categorical_accuracy: 0.6260 - f1_m: 0.6086 - val_loss: 0.9358 - val_categorical_accuracy: 0.7683 - val_f1_m: 0.7200\n",
            "Epoch 2/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.8534 - categorical_accuracy: 0.7688 - f1_m: 0.7835\n",
            "Epoch 2: val_categorical_accuracy improved from 0.76828 to 0.80276, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 74s 305ms/step - loss: 0.8534 - categorical_accuracy: 0.7688 - f1_m: 0.7835 - val_loss: 0.7244 - val_categorical_accuracy: 0.8028 - val_f1_m: 0.7697\n",
            "Epoch 3/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.7505 - categorical_accuracy: 0.8023 - f1_m: 0.8073\n",
            "Epoch 3: val_categorical_accuracy improved from 0.80276 to 0.83172, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 74s 305ms/step - loss: 0.7505 - categorical_accuracy: 0.8023 - f1_m: 0.8073 - val_loss: 0.6689 - val_categorical_accuracy: 0.8317 - val_f1_m: 0.7807\n",
            "Epoch 4/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.6204 - categorical_accuracy: 0.8375 - f1_m: 0.8394\n",
            "Epoch 4: val_categorical_accuracy did not improve from 0.83172\n",
            "241/241 [==============================] - 73s 301ms/step - loss: 0.6204 - categorical_accuracy: 0.8375 - f1_m: 0.8394 - val_loss: 0.6658 - val_categorical_accuracy: 0.8303 - val_f1_m: 0.7890\n",
            "Epoch 5/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.5192 - categorical_accuracy: 0.8552 - f1_m: 0.8598\n",
            "Epoch 5: val_categorical_accuracy improved from 0.83172 to 0.86759, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 73s 304ms/step - loss: 0.5192 - categorical_accuracy: 0.8552 - f1_m: 0.8598 - val_loss: 0.5012 - val_categorical_accuracy: 0.8676 - val_f1_m: 0.8483\n",
            "Epoch 6/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.4505 - categorical_accuracy: 0.8826 - f1_m: 0.8856\n",
            "Epoch 6: val_categorical_accuracy improved from 0.86759 to 0.89241, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 77s 318ms/step - loss: 0.4505 - categorical_accuracy: 0.8826 - f1_m: 0.8856 - val_loss: 0.4191 - val_categorical_accuracy: 0.8924 - val_f1_m: 0.8538\n",
            "Epoch 7/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.4036 - categorical_accuracy: 0.8940 - f1_m: 0.8952\n",
            "Epoch 7: val_categorical_accuracy did not improve from 0.89241\n",
            "241/241 [==============================] - 73s 303ms/step - loss: 0.4036 - categorical_accuracy: 0.8940 - f1_m: 0.8952 - val_loss: 0.4333 - val_categorical_accuracy: 0.8855 - val_f1_m: 0.8690\n",
            "Epoch 8/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.3660 - categorical_accuracy: 0.9059 - f1_m: 0.9062\n",
            "Epoch 8: val_categorical_accuracy improved from 0.89241 to 0.90621, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 74s 308ms/step - loss: 0.3660 - categorical_accuracy: 0.9059 - f1_m: 0.9062 - val_loss: 0.3511 - val_categorical_accuracy: 0.9062 - val_f1_m: 0.8897\n",
            "Epoch 9/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.2488 - categorical_accuracy: 0.9349 - f1_m: 0.9349\n",
            "Epoch 9: val_categorical_accuracy improved from 0.90621 to 0.93517, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 75s 310ms/step - loss: 0.2488 - categorical_accuracy: 0.9349 - f1_m: 0.9349 - val_loss: 0.2572 - val_categorical_accuracy: 0.9352 - val_f1_m: 0.9283\n",
            "Epoch 10/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.2475 - categorical_accuracy: 0.9385 - f1_m: 0.9382\n",
            "Epoch 10: val_categorical_accuracy improved from 0.93517 to 0.96828, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 75s 309ms/step - loss: 0.2475 - categorical_accuracy: 0.9385 - f1_m: 0.9382 - val_loss: 0.1190 - val_categorical_accuracy: 0.9683 - val_f1_m: 0.9641\n",
            "Epoch 11/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1839 - categorical_accuracy: 0.9521 - f1_m: 0.9532\n",
            "Epoch 11: val_categorical_accuracy did not improve from 0.96828\n",
            "241/241 [==============================] - 75s 311ms/step - loss: 0.1839 - categorical_accuracy: 0.9521 - f1_m: 0.9532 - val_loss: 0.3020 - val_categorical_accuracy: 0.9255 - val_f1_m: 0.9228\n",
            "Epoch 12/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1986 - categorical_accuracy: 0.9488 - f1_m: 0.9507\n",
            "Epoch 12: val_categorical_accuracy improved from 0.96828 to 0.99034, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 75s 310ms/step - loss: 0.1986 - categorical_accuracy: 0.9488 - f1_m: 0.9507 - val_loss: 0.0533 - val_categorical_accuracy: 0.9903 - val_f1_m: 0.9848\n",
            "Epoch 13/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1530 - categorical_accuracy: 0.9626 - f1_m: 0.9640\n",
            "Epoch 13: val_categorical_accuracy did not improve from 0.99034\n",
            "241/241 [==============================] - 72s 299ms/step - loss: 0.1530 - categorical_accuracy: 0.9626 - f1_m: 0.9640 - val_loss: 0.1112 - val_categorical_accuracy: 0.9697 - val_f1_m: 0.9669\n",
            "Epoch 14/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1509 - categorical_accuracy: 0.9668 - f1_m: 0.9654\n",
            "Epoch 14: val_categorical_accuracy did not improve from 0.99034\n",
            "241/241 [==============================] - 72s 300ms/step - loss: 0.1509 - categorical_accuracy: 0.9668 - f1_m: 0.9654 - val_loss: 0.1400 - val_categorical_accuracy: 0.9655 - val_f1_m: 0.9628\n",
            "Epoch 15/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1040 - categorical_accuracy: 0.9762 - f1_m: 0.9748\n",
            "Epoch 15: val_categorical_accuracy did not improve from 0.99034\n",
            "241/241 [==============================] - 73s 304ms/step - loss: 0.1040 - categorical_accuracy: 0.9762 - f1_m: 0.9748 - val_loss: 0.0678 - val_categorical_accuracy: 0.9834 - val_f1_m: 0.9807\n",
            "Epoch 16/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1603 - categorical_accuracy: 0.9585 - f1_m: 0.9595\n",
            "Epoch 16: val_categorical_accuracy did not improve from 0.99034\n",
            "241/241 [==============================] - 73s 302ms/step - loss: 0.1603 - categorical_accuracy: 0.9585 - f1_m: 0.9595 - val_loss: 0.1245 - val_categorical_accuracy: 0.9628 - val_f1_m: 0.9628\n",
            "Epoch 17/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1428 - categorical_accuracy: 0.9629 - f1_m: 0.9635\n",
            "Epoch 17: val_categorical_accuracy did not improve from 0.99034\n",
            "241/241 [==============================] - 72s 298ms/step - loss: 0.1428 - categorical_accuracy: 0.9629 - f1_m: 0.9635 - val_loss: 0.3380 - val_categorical_accuracy: 0.9283 - val_f1_m: 0.9241\n",
            "Epoch 18/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0956 - categorical_accuracy: 0.9787 - f1_m: 0.9781\n",
            "Epoch 18: val_categorical_accuracy did not improve from 0.99034\n",
            "241/241 [==============================] - 71s 296ms/step - loss: 0.0956 - categorical_accuracy: 0.9787 - f1_m: 0.9781 - val_loss: 0.1044 - val_categorical_accuracy: 0.9697 - val_f1_m: 0.9697\n",
            "Epoch 19/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1135 - categorical_accuracy: 0.9726 - f1_m: 0.9727\n",
            "Epoch 19: val_categorical_accuracy did not improve from 0.99034\n",
            "241/241 [==============================] - 72s 298ms/step - loss: 0.1135 - categorical_accuracy: 0.9726 - f1_m: 0.9727 - val_loss: 0.1045 - val_categorical_accuracy: 0.9738 - val_f1_m: 0.9710\n",
            "Epoch 20/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0693 - categorical_accuracy: 0.9817 - f1_m: 0.9825\n",
            "Epoch 20: val_categorical_accuracy did not improve from 0.99034\n",
            "241/241 [==============================] - 72s 300ms/step - loss: 0.0693 - categorical_accuracy: 0.9817 - f1_m: 0.9825 - val_loss: 0.0957 - val_categorical_accuracy: 0.9697 - val_f1_m: 0.9669\n",
            "Epoch 21/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1080 - categorical_accuracy: 0.9731 - f1_m: 0.9739\n",
            "Epoch 21: val_categorical_accuracy did not improve from 0.99034\n",
            "241/241 [==============================] - 72s 297ms/step - loss: 0.1080 - categorical_accuracy: 0.9731 - f1_m: 0.9739 - val_loss: 0.0991 - val_categorical_accuracy: 0.9766 - val_f1_m: 0.9766\n",
            "Epoch 22/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0856 - categorical_accuracy: 0.9801 - f1_m: 0.9798\n",
            "Epoch 22: val_categorical_accuracy did not improve from 0.99034\n",
            "241/241 [==============================] - 72s 298ms/step - loss: 0.0856 - categorical_accuracy: 0.9801 - f1_m: 0.9798 - val_loss: 0.0432 - val_categorical_accuracy: 0.9862 - val_f1_m: 0.9862\n",
            "Epoch 23/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1542 - categorical_accuracy: 0.9629 - f1_m: 0.9640\n",
            "Epoch 23: val_categorical_accuracy improved from 0.99034 to 0.99448, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 74s 306ms/step - loss: 0.1542 - categorical_accuracy: 0.9629 - f1_m: 0.9640 - val_loss: 0.0253 - val_categorical_accuracy: 0.9945 - val_f1_m: 0.9945\n",
            "Epoch 24/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0514 - categorical_accuracy: 0.9862 - f1_m: 0.9865\n",
            "Epoch 24: val_categorical_accuracy did not improve from 0.99448\n",
            "241/241 [==============================] - 72s 298ms/step - loss: 0.0514 - categorical_accuracy: 0.9862 - f1_m: 0.9865 - val_loss: 0.0448 - val_categorical_accuracy: 0.9876 - val_f1_m: 0.9876\n",
            "Epoch 25/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0656 - categorical_accuracy: 0.9853 - f1_m: 0.9850\n",
            "Epoch 25: val_categorical_accuracy did not improve from 0.99448\n",
            "241/241 [==============================] - 74s 309ms/step - loss: 0.0656 - categorical_accuracy: 0.9853 - f1_m: 0.9850 - val_loss: 0.0383 - val_categorical_accuracy: 0.9903 - val_f1_m: 0.9903\n",
            "Epoch 26/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1090 - categorical_accuracy: 0.9740 - f1_m: 0.9742\n",
            "Epoch 26: val_categorical_accuracy did not improve from 0.99448\n",
            "241/241 [==============================] - 72s 297ms/step - loss: 0.1090 - categorical_accuracy: 0.9740 - f1_m: 0.9742 - val_loss: 0.1185 - val_categorical_accuracy: 0.9710 - val_f1_m: 0.9669\n",
            "Epoch 27/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0668 - categorical_accuracy: 0.9815 - f1_m: 0.9819\n",
            "Epoch 27: val_categorical_accuracy did not improve from 0.99448\n",
            "241/241 [==============================] - 72s 298ms/step - loss: 0.0668 - categorical_accuracy: 0.9815 - f1_m: 0.9819 - val_loss: 0.0351 - val_categorical_accuracy: 0.9876 - val_f1_m: 0.9876\n",
            "Epoch 28/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0852 - categorical_accuracy: 0.9779 - f1_m: 0.9781\n",
            "Epoch 28: val_categorical_accuracy did not improve from 0.99448\n",
            "241/241 [==============================] - 72s 296ms/step - loss: 0.0852 - categorical_accuracy: 0.9779 - f1_m: 0.9781 - val_loss: 0.0808 - val_categorical_accuracy: 0.9807 - val_f1_m: 0.9793\n",
            "Epoch 29/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0632 - categorical_accuracy: 0.9834 - f1_m: 0.9835\n",
            "Epoch 29: val_categorical_accuracy did not improve from 0.99448\n",
            "241/241 [==============================] - 72s 297ms/step - loss: 0.0632 - categorical_accuracy: 0.9834 - f1_m: 0.9835 - val_loss: 0.0173 - val_categorical_accuracy: 0.9945 - val_f1_m: 0.9945\n",
            "Epoch 30/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0749 - categorical_accuracy: 0.9820 - f1_m: 0.9822\n",
            "Epoch 30: val_categorical_accuracy did not improve from 0.99448\n",
            "241/241 [==============================] - 75s 310ms/step - loss: 0.0749 - categorical_accuracy: 0.9820 - f1_m: 0.9822 - val_loss: 0.0362 - val_categorical_accuracy: 0.9890 - val_f1_m: 0.9876\n",
            "Epoch 31/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0556 - categorical_accuracy: 0.9862 - f1_m: 0.9855\n",
            "Epoch 31: val_categorical_accuracy did not improve from 0.99448\n",
            "241/241 [==============================] - 72s 297ms/step - loss: 0.0556 - categorical_accuracy: 0.9862 - f1_m: 0.9855 - val_loss: 0.0456 - val_categorical_accuracy: 0.9903 - val_f1_m: 0.9903\n",
            "Epoch 32/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0364 - categorical_accuracy: 0.9909 - f1_m: 0.9910\n",
            "Epoch 32: val_categorical_accuracy did not improve from 0.99448\n",
            "241/241 [==============================] - 71s 296ms/step - loss: 0.0364 - categorical_accuracy: 0.9909 - f1_m: 0.9910 - val_loss: 0.1319 - val_categorical_accuracy: 0.9697 - val_f1_m: 0.9669\n",
            "Epoch 33/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0789 - categorical_accuracy: 0.9812 - f1_m: 0.9809\n",
            "Epoch 33: val_categorical_accuracy did not improve from 0.99448\n",
            "241/241 [==============================] - 71s 295ms/step - loss: 0.0789 - categorical_accuracy: 0.9812 - f1_m: 0.9809 - val_loss: 0.0349 - val_categorical_accuracy: 0.9931 - val_f1_m: 0.9903\n",
            "Epoch 34/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0416 - categorical_accuracy: 0.9900 - f1_m: 0.9902\n",
            "Epoch 34: val_categorical_accuracy did not improve from 0.99448\n",
            "241/241 [==============================] - 71s 296ms/step - loss: 0.0416 - categorical_accuracy: 0.9900 - f1_m: 0.9902 - val_loss: 0.0618 - val_categorical_accuracy: 0.9903 - val_f1_m: 0.9890\n",
            "Epoch 35/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0238 - categorical_accuracy: 0.9936 - f1_m: 0.9939\n",
            "Epoch 35: val_categorical_accuracy did not improve from 0.99448\n",
            "241/241 [==============================] - 72s 299ms/step - loss: 0.0238 - categorical_accuracy: 0.9936 - f1_m: 0.9939 - val_loss: 0.0756 - val_categorical_accuracy: 0.9862 - val_f1_m: 0.9862\n",
            "Epoch 36/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0682 - categorical_accuracy: 0.9828 - f1_m: 0.9831\n",
            "Epoch 36: val_categorical_accuracy did not improve from 0.99448\n",
            "241/241 [==============================] - 72s 298ms/step - loss: 0.0682 - categorical_accuracy: 0.9828 - f1_m: 0.9831 - val_loss: 0.0363 - val_categorical_accuracy: 0.9931 - val_f1_m: 0.9903\n",
            "Epoch 37/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0736 - categorical_accuracy: 0.9842 - f1_m: 0.9843\n",
            "Epoch 37: val_categorical_accuracy improved from 0.99448 to 0.99586, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 74s 309ms/step - loss: 0.0736 - categorical_accuracy: 0.9842 - f1_m: 0.9843 - val_loss: 0.0147 - val_categorical_accuracy: 0.9959 - val_f1_m: 0.9959\n",
            "Epoch 38/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0246 - categorical_accuracy: 0.9931 - f1_m: 0.9926\n",
            "Epoch 38: val_categorical_accuracy did not improve from 0.99586\n",
            "241/241 [==============================] - 72s 298ms/step - loss: 0.0246 - categorical_accuracy: 0.9931 - f1_m: 0.9926 - val_loss: 0.0311 - val_categorical_accuracy: 0.9931 - val_f1_m: 0.9931\n",
            "Epoch 39/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0791 - categorical_accuracy: 0.9817 - f1_m: 0.9824\n",
            "Epoch 39: val_categorical_accuracy did not improve from 0.99586\n",
            "241/241 [==============================] - 73s 304ms/step - loss: 0.0791 - categorical_accuracy: 0.9817 - f1_m: 0.9824 - val_loss: 0.0249 - val_categorical_accuracy: 0.9945 - val_f1_m: 0.9945\n",
            "Epoch 40/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0474 - categorical_accuracy: 0.9867 - f1_m: 0.9871\n",
            "Epoch 40: val_categorical_accuracy did not improve from 0.99586\n",
            "241/241 [==============================] - 71s 296ms/step - loss: 0.0474 - categorical_accuracy: 0.9867 - f1_m: 0.9871 - val_loss: 0.1110 - val_categorical_accuracy: 0.9724 - val_f1_m: 0.9697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-c745ba16ed14>:98: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  y_pred = model.predict_generator(test_generator, STEP_SIZE_TEST, verbose=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "907/907 [==============================] - 22s 22ms/step\n",
            "(907,)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.84      0.87       123\n",
            "           1       0.84      0.89      0.86       134\n",
            "           2       0.87      0.78      0.82       140\n",
            "           3       0.74      0.73      0.74       120\n",
            "           4       0.89      0.88      0.88       122\n",
            "           5       0.79      0.89      0.84       126\n",
            "           6       0.86      0.88      0.87       142\n",
            "\n",
            "    accuracy                           0.84       907\n",
            "   macro avg       0.84      0.84      0.84       907\n",
            "weighted avg       0.84      0.84      0.84       907\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Kfold 3\n",
            "Train shape: (3627, 2)\n",
            "Test shape: (907, 2)\n",
            "Found 3627 validated image filenames belonging to 7 classes.\n",
            "Found 725 validated image filenames belonging to 7 classes.\n",
            "Found 907 validated image filenames belonging to 7 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/preprocessing/image.py:1444: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " rescaling_2 (Rescaling)     (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " patching_and_embedding_6 (P  (None, 197, 192)         185664    \n",
            " atchingAndEmbedding)                                            \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 197, 192)          0         \n",
            "                                                                 \n",
            " transformer_encoder_72 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_73 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_74 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_75 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_76 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_77 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_78 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_79 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_80 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_81 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_82 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_83 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " layer_normalization_174 (La  (None, 197, 192)         384       \n",
            " yerNormalization)                                               \n",
            "                                                                 \n",
            " lambda_6 (Lambda)           (None, 192)               0         \n",
            "                                                                 \n",
            " dense_174 (Dense)           (None, 7)                 1351      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,525,767\n",
            "Trainable params: 5,525,767\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-c745ba16ed14>:86: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(generator=train_generator,\n",
            "/usr/local/lib/python3.9/dist-packages/keras/preprocessing/image.py:1861: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/keras/preprocessing/image.py:1884: UserWarning: This ImageDataGenerator specifies `zca_whitening`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 1.6191 - categorical_accuracy: 0.6019 - f1_m: 0.5912\n",
            "Epoch 1: val_categorical_accuracy improved from -inf to 0.73655, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 119s 320ms/step - loss: 1.6191 - categorical_accuracy: 0.6019 - f1_m: 0.5912 - val_loss: 1.1856 - val_categorical_accuracy: 0.7366 - val_f1_m: 0.6924\n",
            "Epoch 2/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.8593 - categorical_accuracy: 0.7647 - f1_m: 0.7777\n",
            "Epoch 2: val_categorical_accuracy improved from 0.73655 to 0.79862, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 75s 310ms/step - loss: 0.8593 - categorical_accuracy: 0.7647 - f1_m: 0.7777 - val_loss: 0.8083 - val_categorical_accuracy: 0.7986 - val_f1_m: 0.7200\n",
            "Epoch 3/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.7766 - categorical_accuracy: 0.7877 - f1_m: 0.7956\n",
            "Epoch 3: val_categorical_accuracy improved from 0.79862 to 0.82069, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 76s 315ms/step - loss: 0.7766 - categorical_accuracy: 0.7877 - f1_m: 0.7956 - val_loss: 0.6892 - val_categorical_accuracy: 0.8207 - val_f1_m: 0.7710\n",
            "Epoch 4/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.6567 - categorical_accuracy: 0.8167 - f1_m: 0.8264\n",
            "Epoch 4: val_categorical_accuracy improved from 0.82069 to 0.83034, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 74s 305ms/step - loss: 0.6567 - categorical_accuracy: 0.8167 - f1_m: 0.8264 - val_loss: 0.6333 - val_categorical_accuracy: 0.8303 - val_f1_m: 0.8000\n",
            "Epoch 5/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.5540 - categorical_accuracy: 0.8502 - f1_m: 0.8557\n",
            "Epoch 5: val_categorical_accuracy improved from 0.83034 to 0.88966, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 74s 307ms/step - loss: 0.5540 - categorical_accuracy: 0.8502 - f1_m: 0.8557 - val_loss: 0.4438 - val_categorical_accuracy: 0.8897 - val_f1_m: 0.8524\n",
            "Epoch 6/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.5313 - categorical_accuracy: 0.8596 - f1_m: 0.8612\n",
            "Epoch 6: val_categorical_accuracy did not improve from 0.88966\n",
            "241/241 [==============================] - 73s 302ms/step - loss: 0.5313 - categorical_accuracy: 0.8596 - f1_m: 0.8612 - val_loss: 0.5398 - val_categorical_accuracy: 0.8648 - val_f1_m: 0.8359\n",
            "Epoch 7/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.4222 - categorical_accuracy: 0.8923 - f1_m: 0.8946\n",
            "Epoch 7: val_categorical_accuracy improved from 0.88966 to 0.93103, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 74s 305ms/step - loss: 0.4222 - categorical_accuracy: 0.8923 - f1_m: 0.8946 - val_loss: 0.2919 - val_categorical_accuracy: 0.9310 - val_f1_m: 0.9034\n",
            "Epoch 8/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.3685 - categorical_accuracy: 0.8987 - f1_m: 0.9005\n",
            "Epoch 8: val_categorical_accuracy improved from 0.93103 to 0.93517, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 73s 304ms/step - loss: 0.3685 - categorical_accuracy: 0.8987 - f1_m: 0.9005 - val_loss: 0.2490 - val_categorical_accuracy: 0.9352 - val_f1_m: 0.9145\n",
            "Epoch 9/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.2964 - categorical_accuracy: 0.9211 - f1_m: 0.9237\n",
            "Epoch 9: val_categorical_accuracy improved from 0.93517 to 0.94483, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 74s 305ms/step - loss: 0.2964 - categorical_accuracy: 0.9211 - f1_m: 0.9237 - val_loss: 0.2153 - val_categorical_accuracy: 0.9448 - val_f1_m: 0.9338\n",
            "Epoch 10/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.2544 - categorical_accuracy: 0.9327 - f1_m: 0.9332\n",
            "Epoch 10: val_categorical_accuracy improved from 0.94483 to 0.96000, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 74s 305ms/step - loss: 0.2544 - categorical_accuracy: 0.9327 - f1_m: 0.9332 - val_loss: 0.1556 - val_categorical_accuracy: 0.9600 - val_f1_m: 0.9545\n",
            "Epoch 11/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.2537 - categorical_accuracy: 0.9347 - f1_m: 0.9328\n",
            "Epoch 11: val_categorical_accuracy did not improve from 0.96000\n",
            "241/241 [==============================] - 73s 302ms/step - loss: 0.2537 - categorical_accuracy: 0.9347 - f1_m: 0.9328 - val_loss: 0.3075 - val_categorical_accuracy: 0.9228 - val_f1_m: 0.9145\n",
            "Epoch 12/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.2205 - categorical_accuracy: 0.9399 - f1_m: 0.9421\n",
            "Epoch 12: val_categorical_accuracy improved from 0.96000 to 0.97103, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 73s 303ms/step - loss: 0.2205 - categorical_accuracy: 0.9399 - f1_m: 0.9421 - val_loss: 0.1200 - val_categorical_accuracy: 0.9710 - val_f1_m: 0.9669\n",
            "Epoch 13/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1420 - categorical_accuracy: 0.9635 - f1_m: 0.9639\n",
            "Epoch 13: val_categorical_accuracy did not improve from 0.97103\n",
            "241/241 [==============================] - 73s 302ms/step - loss: 0.1420 - categorical_accuracy: 0.9635 - f1_m: 0.9639 - val_loss: 0.1916 - val_categorical_accuracy: 0.9559 - val_f1_m: 0.9559\n",
            "Epoch 14/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1595 - categorical_accuracy: 0.9557 - f1_m: 0.9552\n",
            "Epoch 14: val_categorical_accuracy did not improve from 0.97103\n",
            "241/241 [==============================] - 72s 299ms/step - loss: 0.1595 - categorical_accuracy: 0.9557 - f1_m: 0.9552 - val_loss: 0.1433 - val_categorical_accuracy: 0.9628 - val_f1_m: 0.9586\n",
            "Epoch 15/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1714 - categorical_accuracy: 0.9543 - f1_m: 0.9553\n",
            "Epoch 15: val_categorical_accuracy did not improve from 0.97103\n",
            "241/241 [==============================] - 73s 302ms/step - loss: 0.1714 - categorical_accuracy: 0.9543 - f1_m: 0.9553 - val_loss: 0.5368 - val_categorical_accuracy: 0.8759 - val_f1_m: 0.8690\n",
            "Epoch 16/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1290 - categorical_accuracy: 0.9684 - f1_m: 0.9694\n",
            "Epoch 16: val_categorical_accuracy did not improve from 0.97103\n",
            "241/241 [==============================] - 72s 298ms/step - loss: 0.1290 - categorical_accuracy: 0.9684 - f1_m: 0.9694 - val_loss: 0.1203 - val_categorical_accuracy: 0.9600 - val_f1_m: 0.9586\n",
            "Epoch 17/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.2082 - categorical_accuracy: 0.9502 - f1_m: 0.9505\n",
            "Epoch 17: val_categorical_accuracy improved from 0.97103 to 0.97931, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 74s 306ms/step - loss: 0.2082 - categorical_accuracy: 0.9502 - f1_m: 0.9505 - val_loss: 0.0767 - val_categorical_accuracy: 0.9793 - val_f1_m: 0.9779\n",
            "Epoch 18/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0739 - categorical_accuracy: 0.9798 - f1_m: 0.9803\n",
            "Epoch 18: val_categorical_accuracy improved from 0.97931 to 0.99172, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 75s 310ms/step - loss: 0.0739 - categorical_accuracy: 0.9798 - f1_m: 0.9803 - val_loss: 0.0443 - val_categorical_accuracy: 0.9917 - val_f1_m: 0.9890\n",
            "Epoch 19/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1001 - categorical_accuracy: 0.9751 - f1_m: 0.9757\n",
            "Epoch 19: val_categorical_accuracy did not improve from 0.99172\n",
            "241/241 [==============================] - 73s 301ms/step - loss: 0.1001 - categorical_accuracy: 0.9751 - f1_m: 0.9757 - val_loss: 0.1637 - val_categorical_accuracy: 0.9572 - val_f1_m: 0.9545\n",
            "Epoch 20/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0908 - categorical_accuracy: 0.9773 - f1_m: 0.9762\n",
            "Epoch 20: val_categorical_accuracy did not improve from 0.99172\n",
            "241/241 [==============================] - 76s 314ms/step - loss: 0.0908 - categorical_accuracy: 0.9773 - f1_m: 0.9762 - val_loss: 0.0739 - val_categorical_accuracy: 0.9793 - val_f1_m: 0.9779\n",
            "Epoch 21/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0632 - categorical_accuracy: 0.9839 - f1_m: 0.9838\n",
            "Epoch 21: val_categorical_accuracy did not improve from 0.99172\n",
            "241/241 [==============================] - 75s 310ms/step - loss: 0.0632 - categorical_accuracy: 0.9839 - f1_m: 0.9838 - val_loss: 0.2057 - val_categorical_accuracy: 0.9559 - val_f1_m: 0.9531\n",
            "Epoch 22/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1068 - categorical_accuracy: 0.9759 - f1_m: 0.9758\n",
            "Epoch 22: val_categorical_accuracy improved from 0.99172 to 0.99724, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 75s 312ms/step - loss: 0.1068 - categorical_accuracy: 0.9759 - f1_m: 0.9758 - val_loss: 0.0140 - val_categorical_accuracy: 0.9972 - val_f1_m: 0.9972\n",
            "Epoch 23/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0849 - categorical_accuracy: 0.9784 - f1_m: 0.9786\n",
            "Epoch 23: val_categorical_accuracy did not improve from 0.99724\n",
            "241/241 [==============================] - 73s 304ms/step - loss: 0.0849 - categorical_accuracy: 0.9784 - f1_m: 0.9786 - val_loss: 0.0611 - val_categorical_accuracy: 0.9793 - val_f1_m: 0.9793\n",
            "Epoch 24/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0782 - categorical_accuracy: 0.9798 - f1_m: 0.9800\n",
            "Epoch 24: val_categorical_accuracy did not improve from 0.99724\n",
            "241/241 [==============================] - 72s 300ms/step - loss: 0.0782 - categorical_accuracy: 0.9798 - f1_m: 0.9800 - val_loss: 0.0331 - val_categorical_accuracy: 0.9903 - val_f1_m: 0.9903\n",
            "Epoch 25/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1035 - categorical_accuracy: 0.9734 - f1_m: 0.9742\n",
            "Epoch 25: val_categorical_accuracy did not improve from 0.99724\n",
            "241/241 [==============================] - 73s 301ms/step - loss: 0.1035 - categorical_accuracy: 0.9734 - f1_m: 0.9742 - val_loss: 0.1155 - val_categorical_accuracy: 0.9655 - val_f1_m: 0.9641\n",
            "Epoch 26/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0697 - categorical_accuracy: 0.9815 - f1_m: 0.9816\n",
            "Epoch 26: val_categorical_accuracy did not improve from 0.99724\n",
            "241/241 [==============================] - 72s 299ms/step - loss: 0.0697 - categorical_accuracy: 0.9815 - f1_m: 0.9816 - val_loss: 0.0908 - val_categorical_accuracy: 0.9793 - val_f1_m: 0.9779\n",
            "Epoch 27/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0760 - categorical_accuracy: 0.9806 - f1_m: 0.9804\n",
            "Epoch 27: val_categorical_accuracy did not improve from 0.99724\n",
            "241/241 [==============================] - 72s 300ms/step - loss: 0.0760 - categorical_accuracy: 0.9806 - f1_m: 0.9804 - val_loss: 0.0988 - val_categorical_accuracy: 0.9793 - val_f1_m: 0.9766\n",
            "Epoch 28/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0996 - categorical_accuracy: 0.9751 - f1_m: 0.9753\n",
            "Epoch 28: val_categorical_accuracy did not improve from 0.99724\n",
            "241/241 [==============================] - 72s 298ms/step - loss: 0.0996 - categorical_accuracy: 0.9751 - f1_m: 0.9753 - val_loss: 0.0551 - val_categorical_accuracy: 0.9876 - val_f1_m: 0.9876\n",
            "Epoch 29/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0714 - categorical_accuracy: 0.9817 - f1_m: 0.9822\n",
            "Epoch 29: val_categorical_accuracy did not improve from 0.99724\n",
            "241/241 [==============================] - 73s 302ms/step - loss: 0.0714 - categorical_accuracy: 0.9817 - f1_m: 0.9822 - val_loss: 0.0511 - val_categorical_accuracy: 0.9848 - val_f1_m: 0.9821\n",
            "Epoch 30/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0523 - categorical_accuracy: 0.9870 - f1_m: 0.9865\n",
            "Epoch 30: val_categorical_accuracy did not improve from 0.99724\n",
            "241/241 [==============================] - 72s 297ms/step - loss: 0.0523 - categorical_accuracy: 0.9870 - f1_m: 0.9865 - val_loss: 0.1378 - val_categorical_accuracy: 0.9697 - val_f1_m: 0.9683\n",
            "Epoch 31/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0846 - categorical_accuracy: 0.9776 - f1_m: 0.9778\n",
            "Epoch 31: val_categorical_accuracy did not improve from 0.99724\n",
            "241/241 [==============================] - 72s 300ms/step - loss: 0.0846 - categorical_accuracy: 0.9776 - f1_m: 0.9778 - val_loss: 0.1253 - val_categorical_accuracy: 0.9655 - val_f1_m: 0.9655\n",
            "Epoch 32/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0513 - categorical_accuracy: 0.9864 - f1_m: 0.9860\n",
            "Epoch 32: val_categorical_accuracy did not improve from 0.99724\n",
            "241/241 [==============================] - 72s 300ms/step - loss: 0.0513 - categorical_accuracy: 0.9864 - f1_m: 0.9860 - val_loss: 0.0266 - val_categorical_accuracy: 0.9931 - val_f1_m: 0.9931\n",
            "Epoch 33/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0439 - categorical_accuracy: 0.9895 - f1_m: 0.9893\n",
            "Epoch 33: val_categorical_accuracy did not improve from 0.99724\n",
            "241/241 [==============================] - 72s 300ms/step - loss: 0.0439 - categorical_accuracy: 0.9895 - f1_m: 0.9893 - val_loss: 0.0142 - val_categorical_accuracy: 0.9972 - val_f1_m: 0.9972\n",
            "Epoch 34/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0553 - categorical_accuracy: 0.9867 - f1_m: 0.9870\n",
            "Epoch 34: val_categorical_accuracy did not improve from 0.99724\n",
            "241/241 [==============================] - 73s 302ms/step - loss: 0.0553 - categorical_accuracy: 0.9867 - f1_m: 0.9870 - val_loss: 0.0653 - val_categorical_accuracy: 0.9848 - val_f1_m: 0.9848\n",
            "Epoch 35/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0445 - categorical_accuracy: 0.9903 - f1_m: 0.9901\n",
            "Epoch 35: val_categorical_accuracy did not improve from 0.99724\n",
            "241/241 [==============================] - 73s 301ms/step - loss: 0.0445 - categorical_accuracy: 0.9903 - f1_m: 0.9901 - val_loss: 0.0513 - val_categorical_accuracy: 0.9876 - val_f1_m: 0.9876\n",
            "Epoch 36/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0811 - categorical_accuracy: 0.9812 - f1_m: 0.9802\n",
            "Epoch 36: val_categorical_accuracy did not improve from 0.99724\n",
            "241/241 [==============================] - 73s 302ms/step - loss: 0.0811 - categorical_accuracy: 0.9812 - f1_m: 0.9802 - val_loss: 0.0331 - val_categorical_accuracy: 0.9917 - val_f1_m: 0.9917\n",
            "Epoch 37/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0533 - categorical_accuracy: 0.9875 - f1_m: 0.9877\n",
            "Epoch 37: val_categorical_accuracy did not improve from 0.99724\n",
            "241/241 [==============================] - 75s 311ms/step - loss: 0.0533 - categorical_accuracy: 0.9875 - f1_m: 0.9877 - val_loss: 0.0330 - val_categorical_accuracy: 0.9903 - val_f1_m: 0.9903\n",
            "Epoch 38/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0274 - categorical_accuracy: 0.9934 - f1_m: 0.9932\n",
            "Epoch 38: val_categorical_accuracy did not improve from 0.99724\n",
            "241/241 [==============================] - 75s 310ms/step - loss: 0.0274 - categorical_accuracy: 0.9934 - f1_m: 0.9932 - val_loss: 0.0327 - val_categorical_accuracy: 0.9917 - val_f1_m: 0.9917\n",
            "Epoch 39/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0372 - categorical_accuracy: 0.9900 - f1_m: 0.9901\n",
            "Epoch 39: val_categorical_accuracy did not improve from 0.99724\n",
            "241/241 [==============================] - 74s 306ms/step - loss: 0.0372 - categorical_accuracy: 0.9900 - f1_m: 0.9901 - val_loss: 0.0468 - val_categorical_accuracy: 0.9862 - val_f1_m: 0.9848\n",
            "Epoch 40/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0718 - categorical_accuracy: 0.9820 - f1_m: 0.9825\n",
            "Epoch 40: val_categorical_accuracy did not improve from 0.99724\n",
            "241/241 [==============================] - 72s 300ms/step - loss: 0.0718 - categorical_accuracy: 0.9820 - f1_m: 0.9825 - val_loss: 0.0272 - val_categorical_accuracy: 0.9945 - val_f1_m: 0.9945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-c745ba16ed14>:98: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  y_pred = model.predict_generator(test_generator, STEP_SIZE_TEST, verbose=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "907/907 [==============================] - 23s 24ms/step\n",
            "(907,)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.84      0.86       115\n",
            "           1       0.81      0.93      0.87       125\n",
            "           2       0.85      0.86      0.86       129\n",
            "           3       0.74      0.84      0.79       128\n",
            "           4       0.94      0.89      0.91       123\n",
            "           5       0.89      0.83      0.86       150\n",
            "           6       0.94      0.84      0.89       137\n",
            "\n",
            "    accuracy                           0.86       907\n",
            "   macro avg       0.86      0.86      0.86       907\n",
            "weighted avg       0.87      0.86      0.86       907\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Kfold 4\n",
            "Train shape: (3627, 2)\n",
            "Test shape: (907, 2)\n",
            "Found 3627 validated image filenames belonging to 7 classes.\n",
            "Found 725 validated image filenames belonging to 7 classes.\n",
            "Found 907 validated image filenames belonging to 7 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/preprocessing/image.py:1444: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " rescaling_2 (Rescaling)     (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " patching_and_embedding_7 (P  (None, 197, 192)         185664    \n",
            " atchingAndEmbedding)                                            \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 197, 192)          0         \n",
            "                                                                 \n",
            " transformer_encoder_84 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_85 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_86 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_87 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_88 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_89 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_90 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_91 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_92 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_93 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_94 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_95 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " layer_normalization_199 (La  (None, 197, 192)         384       \n",
            " yerNormalization)                                               \n",
            "                                                                 \n",
            " lambda_7 (Lambda)           (None, 192)               0         \n",
            "                                                                 \n",
            " dense_199 (Dense)           (None, 7)                 1351      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,525,767\n",
            "Trainable params: 5,525,767\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-c745ba16ed14>:86: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(generator=train_generator,\n",
            "/usr/local/lib/python3.9/dist-packages/keras/preprocessing/image.py:1861: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/keras/preprocessing/image.py:1884: UserWarning: This ImageDataGenerator specifies `zca_whitening`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 1.6592 - categorical_accuracy: 0.6276 - f1_m: 0.6349\n",
            "Epoch 1: val_categorical_accuracy improved from -inf to 0.74207, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 119s 320ms/step - loss: 1.6592 - categorical_accuracy: 0.6276 - f1_m: 0.6349 - val_loss: 0.9494 - val_categorical_accuracy: 0.7421 - val_f1_m: 0.6979\n",
            "Epoch 2/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.8246 - categorical_accuracy: 0.7749 - f1_m: 0.7899\n",
            "Epoch 2: val_categorical_accuracy improved from 0.74207 to 0.80828, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 74s 306ms/step - loss: 0.8246 - categorical_accuracy: 0.7749 - f1_m: 0.7899 - val_loss: 0.7373 - val_categorical_accuracy: 0.8083 - val_f1_m: 0.7697\n",
            "Epoch 3/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.7146 - categorical_accuracy: 0.8056 - f1_m: 0.8126\n",
            "Epoch 3: val_categorical_accuracy did not improve from 0.80828\n",
            "241/241 [==============================] - 75s 310ms/step - loss: 0.7146 - categorical_accuracy: 0.8056 - f1_m: 0.8126 - val_loss: 0.8591 - val_categorical_accuracy: 0.8000 - val_f1_m: 0.7641\n",
            "Epoch 4/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.6805 - categorical_accuracy: 0.8159 - f1_m: 0.8229\n",
            "Epoch 4: val_categorical_accuracy improved from 0.80828 to 0.86897, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 74s 307ms/step - loss: 0.6805 - categorical_accuracy: 0.8159 - f1_m: 0.8229 - val_loss: 0.4878 - val_categorical_accuracy: 0.8690 - val_f1_m: 0.8372\n",
            "Epoch 5/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.5305 - categorical_accuracy: 0.8602 - f1_m: 0.8622\n",
            "Epoch 5: val_categorical_accuracy improved from 0.86897 to 0.87172, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 76s 315ms/step - loss: 0.5305 - categorical_accuracy: 0.8602 - f1_m: 0.8622 - val_loss: 0.4724 - val_categorical_accuracy: 0.8717 - val_f1_m: 0.8428\n",
            "Epoch 6/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.4800 - categorical_accuracy: 0.8732 - f1_m: 0.8742\n",
            "Epoch 6: val_categorical_accuracy improved from 0.87172 to 0.91310, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 74s 309ms/step - loss: 0.4800 - categorical_accuracy: 0.8732 - f1_m: 0.8742 - val_loss: 0.3724 - val_categorical_accuracy: 0.9131 - val_f1_m: 0.8828\n",
            "Epoch 7/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.4181 - categorical_accuracy: 0.8870 - f1_m: 0.8924\n",
            "Epoch 7: val_categorical_accuracy did not improve from 0.91310\n",
            "241/241 [==============================] - 73s 302ms/step - loss: 0.4181 - categorical_accuracy: 0.8870 - f1_m: 0.8924 - val_loss: 0.3990 - val_categorical_accuracy: 0.9048 - val_f1_m: 0.8814\n",
            "Epoch 8/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.3579 - categorical_accuracy: 0.9031 - f1_m: 0.9044\n",
            "Epoch 8: val_categorical_accuracy improved from 0.91310 to 0.95034, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 74s 308ms/step - loss: 0.3579 - categorical_accuracy: 0.9031 - f1_m: 0.9044 - val_loss: 0.2183 - val_categorical_accuracy: 0.9503 - val_f1_m: 0.9366\n",
            "Epoch 9/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.2921 - categorical_accuracy: 0.9217 - f1_m: 0.9231\n",
            "Epoch 9: val_categorical_accuracy improved from 0.95034 to 0.96138, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 74s 307ms/step - loss: 0.2921 - categorical_accuracy: 0.9217 - f1_m: 0.9231 - val_loss: 0.1467 - val_categorical_accuracy: 0.9614 - val_f1_m: 0.9531\n",
            "Epoch 10/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.2513 - categorical_accuracy: 0.9319 - f1_m: 0.9335\n",
            "Epoch 10: val_categorical_accuracy improved from 0.96138 to 0.96552, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 74s 308ms/step - loss: 0.2513 - categorical_accuracy: 0.9319 - f1_m: 0.9335 - val_loss: 0.1610 - val_categorical_accuracy: 0.9655 - val_f1_m: 0.9545\n",
            "Epoch 11/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.2239 - categorical_accuracy: 0.9405 - f1_m: 0.9419\n",
            "Epoch 11: val_categorical_accuracy improved from 0.96552 to 0.96690, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 75s 313ms/step - loss: 0.2239 - categorical_accuracy: 0.9405 - f1_m: 0.9419 - val_loss: 0.1402 - val_categorical_accuracy: 0.9669 - val_f1_m: 0.9600\n",
            "Epoch 12/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1752 - categorical_accuracy: 0.9543 - f1_m: 0.9555\n",
            "Epoch 12: val_categorical_accuracy improved from 0.96690 to 0.97655, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 77s 318ms/step - loss: 0.1752 - categorical_accuracy: 0.9543 - f1_m: 0.9555 - val_loss: 0.0974 - val_categorical_accuracy: 0.9766 - val_f1_m: 0.9752\n",
            "Epoch 13/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1712 - categorical_accuracy: 0.9571 - f1_m: 0.9573\n",
            "Epoch 13: val_categorical_accuracy did not improve from 0.97655\n",
            "241/241 [==============================] - 77s 319ms/step - loss: 0.1712 - categorical_accuracy: 0.9571 - f1_m: 0.9573 - val_loss: 0.1081 - val_categorical_accuracy: 0.9738 - val_f1_m: 0.9697\n",
            "Epoch 14/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.2108 - categorical_accuracy: 0.9460 - f1_m: 0.9470\n",
            "Epoch 14: val_categorical_accuracy improved from 0.97655 to 0.98621, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 76s 316ms/step - loss: 0.2108 - categorical_accuracy: 0.9460 - f1_m: 0.9470 - val_loss: 0.0661 - val_categorical_accuracy: 0.9862 - val_f1_m: 0.9821\n",
            "Epoch 15/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1064 - categorical_accuracy: 0.9709 - f1_m: 0.9712\n",
            "Epoch 15: val_categorical_accuracy did not improve from 0.98621\n",
            "241/241 [==============================] - 73s 303ms/step - loss: 0.1064 - categorical_accuracy: 0.9709 - f1_m: 0.9712 - val_loss: 0.1807 - val_categorical_accuracy: 0.9517 - val_f1_m: 0.9490\n",
            "Epoch 16/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1035 - categorical_accuracy: 0.9718 - f1_m: 0.9719\n",
            "Epoch 16: val_categorical_accuracy did not improve from 0.98621\n",
            "241/241 [==============================] - 72s 299ms/step - loss: 0.1035 - categorical_accuracy: 0.9718 - f1_m: 0.9719 - val_loss: 0.0586 - val_categorical_accuracy: 0.9834 - val_f1_m: 0.9821\n",
            "Epoch 17/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1198 - categorical_accuracy: 0.9715 - f1_m: 0.9714\n",
            "Epoch 17: val_categorical_accuracy did not improve from 0.98621\n",
            "241/241 [==============================] - 72s 297ms/step - loss: 0.1198 - categorical_accuracy: 0.9715 - f1_m: 0.9714 - val_loss: 0.2831 - val_categorical_accuracy: 0.9310 - val_f1_m: 0.9228\n",
            "Epoch 18/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1411 - categorical_accuracy: 0.9640 - f1_m: 0.9640\n",
            "Epoch 18: val_categorical_accuracy improved from 0.98621 to 0.98759, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 76s 316ms/step - loss: 0.1411 - categorical_accuracy: 0.9640 - f1_m: 0.9640 - val_loss: 0.0463 - val_categorical_accuracy: 0.9876 - val_f1_m: 0.9876\n",
            "Epoch 19/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1212 - categorical_accuracy: 0.9690 - f1_m: 0.9686\n",
            "Epoch 19: val_categorical_accuracy did not improve from 0.98759\n",
            "241/241 [==============================] - 73s 304ms/step - loss: 0.1212 - categorical_accuracy: 0.9690 - f1_m: 0.9686 - val_loss: 0.0661 - val_categorical_accuracy: 0.9848 - val_f1_m: 0.9848\n",
            "Epoch 20/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1155 - categorical_accuracy: 0.9709 - f1_m: 0.9715\n",
            "Epoch 20: val_categorical_accuracy did not improve from 0.98759\n",
            "241/241 [==============================] - 74s 306ms/step - loss: 0.1155 - categorical_accuracy: 0.9709 - f1_m: 0.9715 - val_loss: 0.0662 - val_categorical_accuracy: 0.9848 - val_f1_m: 0.9834\n",
            "Epoch 21/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1047 - categorical_accuracy: 0.9743 - f1_m: 0.9743\n",
            "Epoch 21: val_categorical_accuracy did not improve from 0.98759\n",
            "241/241 [==============================] - 72s 300ms/step - loss: 0.1047 - categorical_accuracy: 0.9743 - f1_m: 0.9743 - val_loss: 0.0499 - val_categorical_accuracy: 0.9876 - val_f1_m: 0.9876\n",
            "Epoch 22/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0969 - categorical_accuracy: 0.9748 - f1_m: 0.9737\n",
            "Epoch 22: val_categorical_accuracy did not improve from 0.98759\n",
            "241/241 [==============================] - 72s 298ms/step - loss: 0.0969 - categorical_accuracy: 0.9748 - f1_m: 0.9737 - val_loss: 0.0826 - val_categorical_accuracy: 0.9793 - val_f1_m: 0.9779\n",
            "Epoch 23/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0810 - categorical_accuracy: 0.9779 - f1_m: 0.9786\n",
            "Epoch 23: val_categorical_accuracy did not improve from 0.98759\n",
            "241/241 [==============================] - 73s 303ms/step - loss: 0.0810 - categorical_accuracy: 0.9779 - f1_m: 0.9786 - val_loss: 0.0616 - val_categorical_accuracy: 0.9876 - val_f1_m: 0.9876\n",
            "Epoch 24/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0848 - categorical_accuracy: 0.9795 - f1_m: 0.9789\n",
            "Epoch 24: val_categorical_accuracy did not improve from 0.98759\n",
            "241/241 [==============================] - 72s 298ms/step - loss: 0.0848 - categorical_accuracy: 0.9795 - f1_m: 0.9789 - val_loss: 0.1248 - val_categorical_accuracy: 0.9669 - val_f1_m: 0.9628\n",
            "Epoch 25/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1066 - categorical_accuracy: 0.9731 - f1_m: 0.9731\n",
            "Epoch 25: val_categorical_accuracy did not improve from 0.98759\n",
            "241/241 [==============================] - 72s 299ms/step - loss: 0.1066 - categorical_accuracy: 0.9731 - f1_m: 0.9731 - val_loss: 0.0867 - val_categorical_accuracy: 0.9793 - val_f1_m: 0.9738\n",
            "Epoch 26/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0396 - categorical_accuracy: 0.9895 - f1_m: 0.9893\n",
            "Epoch 26: val_categorical_accuracy did not improve from 0.98759\n",
            "241/241 [==============================] - 72s 300ms/step - loss: 0.0396 - categorical_accuracy: 0.9895 - f1_m: 0.9893 - val_loss: 0.0635 - val_categorical_accuracy: 0.9848 - val_f1_m: 0.9848\n",
            "Epoch 27/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0891 - categorical_accuracy: 0.9784 - f1_m: 0.9789\n",
            "Epoch 27: val_categorical_accuracy did not improve from 0.98759\n",
            "241/241 [==============================] - 72s 299ms/step - loss: 0.0891 - categorical_accuracy: 0.9784 - f1_m: 0.9789 - val_loss: 0.0727 - val_categorical_accuracy: 0.9821 - val_f1_m: 0.9821\n",
            "Epoch 28/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0902 - categorical_accuracy: 0.9779 - f1_m: 0.9777\n",
            "Epoch 28: val_categorical_accuracy did not improve from 0.98759\n",
            "241/241 [==============================] - 72s 300ms/step - loss: 0.0902 - categorical_accuracy: 0.9779 - f1_m: 0.9777 - val_loss: 0.0626 - val_categorical_accuracy: 0.9848 - val_f1_m: 0.9834\n",
            "Epoch 29/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0550 - categorical_accuracy: 0.9875 - f1_m: 0.9872\n",
            "Epoch 29: val_categorical_accuracy did not improve from 0.98759\n",
            "241/241 [==============================] - 73s 302ms/step - loss: 0.0550 - categorical_accuracy: 0.9875 - f1_m: 0.9872 - val_loss: 0.1089 - val_categorical_accuracy: 0.9752 - val_f1_m: 0.9724\n",
            "Epoch 30/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0808 - categorical_accuracy: 0.9803 - f1_m: 0.9801\n",
            "Epoch 30: val_categorical_accuracy improved from 0.98759 to 0.99034, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 73s 304ms/step - loss: 0.0808 - categorical_accuracy: 0.9803 - f1_m: 0.9801 - val_loss: 0.0392 - val_categorical_accuracy: 0.9903 - val_f1_m: 0.9890\n",
            "Epoch 31/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0395 - categorical_accuracy: 0.9903 - f1_m: 0.9900\n",
            "Epoch 31: val_categorical_accuracy improved from 0.99034 to 0.99448, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 74s 306ms/step - loss: 0.0395 - categorical_accuracy: 0.9903 - f1_m: 0.9900 - val_loss: 0.0235 - val_categorical_accuracy: 0.9945 - val_f1_m: 0.9945\n",
            "Epoch 32/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0248 - categorical_accuracy: 0.9931 - f1_m: 0.9933\n",
            "Epoch 32: val_categorical_accuracy did not improve from 0.99448\n",
            "241/241 [==============================] - 75s 311ms/step - loss: 0.0248 - categorical_accuracy: 0.9931 - f1_m: 0.9933 - val_loss: 0.0770 - val_categorical_accuracy: 0.9821 - val_f1_m: 0.9821\n",
            "Epoch 33/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1299 - categorical_accuracy: 0.9734 - f1_m: 0.9729\n",
            "Epoch 33: val_categorical_accuracy did not improve from 0.99448\n",
            "241/241 [==============================] - 74s 307ms/step - loss: 0.1299 - categorical_accuracy: 0.9734 - f1_m: 0.9729 - val_loss: 0.0223 - val_categorical_accuracy: 0.9931 - val_f1_m: 0.9931\n",
            "Epoch 34/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0294 - categorical_accuracy: 0.9931 - f1_m: 0.9931\n",
            "Epoch 34: val_categorical_accuracy improved from 0.99448 to 0.99862, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 73s 304ms/step - loss: 0.0294 - categorical_accuracy: 0.9931 - f1_m: 0.9931 - val_loss: 0.0051 - val_categorical_accuracy: 0.9986 - val_f1_m: 0.9986\n",
            "Epoch 35/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0220 - categorical_accuracy: 0.9956 - f1_m: 0.9953\n",
            "Epoch 35: val_categorical_accuracy did not improve from 0.99862\n",
            "241/241 [==============================] - 73s 304ms/step - loss: 0.0220 - categorical_accuracy: 0.9956 - f1_m: 0.9953 - val_loss: 0.0334 - val_categorical_accuracy: 0.9903 - val_f1_m: 0.9903\n",
            "Epoch 36/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0527 - categorical_accuracy: 0.9864 - f1_m: 0.9870\n",
            "Epoch 36: val_categorical_accuracy did not improve from 0.99862\n",
            "241/241 [==============================] - 72s 298ms/step - loss: 0.0527 - categorical_accuracy: 0.9864 - f1_m: 0.9870 - val_loss: 0.0253 - val_categorical_accuracy: 0.9917 - val_f1_m: 0.9917\n",
            "Epoch 37/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0894 - categorical_accuracy: 0.9798 - f1_m: 0.9799\n",
            "Epoch 37: val_categorical_accuracy did not improve from 0.99862\n",
            "241/241 [==============================] - 72s 297ms/step - loss: 0.0894 - categorical_accuracy: 0.9798 - f1_m: 0.9799 - val_loss: 0.0729 - val_categorical_accuracy: 0.9834 - val_f1_m: 0.9821\n",
            "Epoch 38/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0593 - categorical_accuracy: 0.9862 - f1_m: 0.9863\n",
            "Epoch 38: val_categorical_accuracy did not improve from 0.99862\n",
            "241/241 [==============================] - 72s 299ms/step - loss: 0.0593 - categorical_accuracy: 0.9862 - f1_m: 0.9863 - val_loss: 0.0289 - val_categorical_accuracy: 0.9931 - val_f1_m: 0.9931\n",
            "Epoch 39/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0585 - categorical_accuracy: 0.9837 - f1_m: 0.9838\n",
            "Epoch 39: val_categorical_accuracy did not improve from 0.99862\n",
            "241/241 [==============================] - 72s 298ms/step - loss: 0.0585 - categorical_accuracy: 0.9837 - f1_m: 0.9838 - val_loss: 0.0368 - val_categorical_accuracy: 0.9917 - val_f1_m: 0.9917\n",
            "Epoch 40/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0440 - categorical_accuracy: 0.9895 - f1_m: 0.9893\n",
            "Epoch 40: val_categorical_accuracy did not improve from 0.99862\n",
            "241/241 [==============================] - 74s 307ms/step - loss: 0.0440 - categorical_accuracy: 0.9895 - f1_m: 0.9893 - val_loss: 0.0305 - val_categorical_accuracy: 0.9917 - val_f1_m: 0.9917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-c745ba16ed14>:98: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  y_pred = model.predict_generator(test_generator, STEP_SIZE_TEST, verbose=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "907/907 [==============================] - 22s 22ms/step\n",
            "(907,)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.89      0.88       125\n",
            "           1       0.88      0.82      0.85       143\n",
            "           2       0.75      0.82      0.79       125\n",
            "           3       0.85      0.76      0.80       152\n",
            "           4       0.89      0.87      0.88       119\n",
            "           5       0.77      0.82      0.79       122\n",
            "           6       0.87      0.92      0.89       121\n",
            "\n",
            "    accuracy                           0.84       907\n",
            "   macro avg       0.84      0.84      0.84       907\n",
            "weighted avg       0.84      0.84      0.84       907\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Kfold 5\n",
            "Train shape: (3628, 2)\n",
            "Test shape: (906, 2)\n",
            "Found 3628 validated image filenames belonging to 7 classes.\n",
            "Found 725 validated image filenames belonging to 7 classes.\n",
            "Found 906 validated image filenames belonging to 7 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/preprocessing/image.py:1444: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_9 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " rescaling_2 (Rescaling)     (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " patching_and_embedding_8 (P  (None, 197, 192)         185664    \n",
            " atchingAndEmbedding)                                            \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 197, 192)          0         \n",
            "                                                                 \n",
            " transformer_encoder_96 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_97 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_98 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_99 (Tra  (None, 197, 192)         444864    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_100 (Tr  (None, 197, 192)         444864    \n",
            " ansformerEncoder)                                               \n",
            "                                                                 \n",
            " transformer_encoder_101 (Tr  (None, 197, 192)         444864    \n",
            " ansformerEncoder)                                               \n",
            "                                                                 \n",
            " transformer_encoder_102 (Tr  (None, 197, 192)         444864    \n",
            " ansformerEncoder)                                               \n",
            "                                                                 \n",
            " transformer_encoder_103 (Tr  (None, 197, 192)         444864    \n",
            " ansformerEncoder)                                               \n",
            "                                                                 \n",
            " transformer_encoder_104 (Tr  (None, 197, 192)         444864    \n",
            " ansformerEncoder)                                               \n",
            "                                                                 \n",
            " transformer_encoder_105 (Tr  (None, 197, 192)         444864    \n",
            " ansformerEncoder)                                               \n",
            "                                                                 \n",
            " transformer_encoder_106 (Tr  (None, 197, 192)         444864    \n",
            " ansformerEncoder)                                               \n",
            "                                                                 \n",
            " transformer_encoder_107 (Tr  (None, 197, 192)         444864    \n",
            " ansformerEncoder)                                               \n",
            "                                                                 \n",
            " layer_normalization_224 (La  (None, 197, 192)         384       \n",
            " yerNormalization)                                               \n",
            "                                                                 \n",
            " lambda_8 (Lambda)           (None, 192)               0         \n",
            "                                                                 \n",
            " dense_224 (Dense)           (None, 7)                 1351      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,525,767\n",
            "Trainable params: 5,525,767\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-c745ba16ed14>:86: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(generator=train_generator,\n",
            "/usr/local/lib/python3.9/dist-packages/keras/preprocessing/image.py:1861: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/keras/preprocessing/image.py:1884: UserWarning: This ImageDataGenerator specifies `zca_whitening`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 1.5720 - categorical_accuracy: 0.6263 - f1_m: 0.6260\n",
            "Epoch 1: val_categorical_accuracy improved from -inf to 0.79724, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 118s 317ms/step - loss: 1.5720 - categorical_accuracy: 0.6263 - f1_m: 0.6260 - val_loss: 0.8971 - val_categorical_accuracy: 0.7972 - val_f1_m: 0.7366\n",
            "Epoch 2/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.8160 - categorical_accuracy: 0.7783 - f1_m: 0.7894\n",
            "Epoch 2: val_categorical_accuracy improved from 0.79724 to 0.84138, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 73s 303ms/step - loss: 0.8160 - categorical_accuracy: 0.7783 - f1_m: 0.7894 - val_loss: 0.6714 - val_categorical_accuracy: 0.8414 - val_f1_m: 0.7614\n",
            "Epoch 3/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.7573 - categorical_accuracy: 0.7921 - f1_m: 0.8011\n",
            "Epoch 3: val_categorical_accuracy did not improve from 0.84138\n",
            "241/241 [==============================] - 72s 299ms/step - loss: 0.7573 - categorical_accuracy: 0.7921 - f1_m: 0.8011 - val_loss: 0.7284 - val_categorical_accuracy: 0.8110 - val_f1_m: 0.7600\n",
            "Epoch 4/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.5954 - categorical_accuracy: 0.8381 - f1_m: 0.8409\n",
            "Epoch 4: val_categorical_accuracy improved from 0.84138 to 0.89931, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 73s 304ms/step - loss: 0.5954 - categorical_accuracy: 0.8381 - f1_m: 0.8409 - val_loss: 0.3936 - val_categorical_accuracy: 0.8993 - val_f1_m: 0.8717\n",
            "Epoch 5/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.5585 - categorical_accuracy: 0.8508 - f1_m: 0.8557\n",
            "Epoch 5: val_categorical_accuracy did not improve from 0.89931\n",
            "241/241 [==============================] - 74s 308ms/step - loss: 0.5585 - categorical_accuracy: 0.8508 - f1_m: 0.8557 - val_loss: 0.4105 - val_categorical_accuracy: 0.8952 - val_f1_m: 0.8662\n",
            "Epoch 6/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.4593 - categorical_accuracy: 0.8746 - f1_m: 0.8795\n",
            "Epoch 6: val_categorical_accuracy improved from 0.89931 to 0.92414, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 74s 305ms/step - loss: 0.4593 - categorical_accuracy: 0.8746 - f1_m: 0.8795 - val_loss: 0.3424 - val_categorical_accuracy: 0.9241 - val_f1_m: 0.8910\n",
            "Epoch 7/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.4408 - categorical_accuracy: 0.8890 - f1_m: 0.8886\n",
            "Epoch 7: val_categorical_accuracy improved from 0.92414 to 0.94759, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 74s 306ms/step - loss: 0.4408 - categorical_accuracy: 0.8890 - f1_m: 0.8886 - val_loss: 0.2409 - val_categorical_accuracy: 0.9476 - val_f1_m: 0.9214\n",
            "Epoch 8/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.3299 - categorical_accuracy: 0.9136 - f1_m: 0.9154\n",
            "Epoch 8: val_categorical_accuracy improved from 0.94759 to 0.95172, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 73s 303ms/step - loss: 0.3299 - categorical_accuracy: 0.9136 - f1_m: 0.9154 - val_loss: 0.2000 - val_categorical_accuracy: 0.9517 - val_f1_m: 0.9393\n",
            "Epoch 9/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.2613 - categorical_accuracy: 0.9308 - f1_m: 0.9313\n",
            "Epoch 9: val_categorical_accuracy did not improve from 0.95172\n",
            "241/241 [==============================] - 74s 306ms/step - loss: 0.2613 - categorical_accuracy: 0.9308 - f1_m: 0.9313 - val_loss: 0.2082 - val_categorical_accuracy: 0.9517 - val_f1_m: 0.9407\n",
            "Epoch 10/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.3021 - categorical_accuracy: 0.9228 - f1_m: 0.9260\n",
            "Epoch 10: val_categorical_accuracy did not improve from 0.95172\n",
            "241/241 [==============================] - 75s 312ms/step - loss: 0.3021 - categorical_accuracy: 0.9228 - f1_m: 0.9260 - val_loss: 0.2379 - val_categorical_accuracy: 0.9352 - val_f1_m: 0.9269\n",
            "Epoch 11/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.2090 - categorical_accuracy: 0.9466 - f1_m: 0.9469\n",
            "Epoch 11: val_categorical_accuracy improved from 0.95172 to 0.97103, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 76s 317ms/step - loss: 0.2090 - categorical_accuracy: 0.9466 - f1_m: 0.9469 - val_loss: 0.1165 - val_categorical_accuracy: 0.9710 - val_f1_m: 0.9600\n",
            "Epoch 12/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1822 - categorical_accuracy: 0.9507 - f1_m: 0.9518\n",
            "Epoch 12: val_categorical_accuracy did not improve from 0.97103\n",
            "241/241 [==============================] - 73s 301ms/step - loss: 0.1822 - categorical_accuracy: 0.9507 - f1_m: 0.9518 - val_loss: 0.1943 - val_categorical_accuracy: 0.9490 - val_f1_m: 0.9448\n",
            "Epoch 13/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.2063 - categorical_accuracy: 0.9466 - f1_m: 0.9486\n",
            "Epoch 13: val_categorical_accuracy improved from 0.97103 to 0.99172, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 73s 305ms/step - loss: 0.2063 - categorical_accuracy: 0.9466 - f1_m: 0.9486 - val_loss: 0.0426 - val_categorical_accuracy: 0.9917 - val_f1_m: 0.9890\n",
            "Epoch 14/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1213 - categorical_accuracy: 0.9673 - f1_m: 0.9683\n",
            "Epoch 14: val_categorical_accuracy did not improve from 0.99172\n",
            "241/241 [==============================] - 74s 308ms/step - loss: 0.1213 - categorical_accuracy: 0.9673 - f1_m: 0.9683 - val_loss: 0.0562 - val_categorical_accuracy: 0.9862 - val_f1_m: 0.9848\n",
            "Epoch 15/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1413 - categorical_accuracy: 0.9632 - f1_m: 0.9637\n",
            "Epoch 15: val_categorical_accuracy did not improve from 0.99172\n",
            "241/241 [==============================] - 73s 303ms/step - loss: 0.1413 - categorical_accuracy: 0.9632 - f1_m: 0.9637 - val_loss: 0.2881 - val_categorical_accuracy: 0.9338 - val_f1_m: 0.9255\n",
            "Epoch 16/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1679 - categorical_accuracy: 0.9604 - f1_m: 0.9591\n",
            "Epoch 16: val_categorical_accuracy did not improve from 0.99172\n",
            "241/241 [==============================] - 72s 297ms/step - loss: 0.1679 - categorical_accuracy: 0.9604 - f1_m: 0.9591 - val_loss: 0.0909 - val_categorical_accuracy: 0.9779 - val_f1_m: 0.9779\n",
            "Epoch 17/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1300 - categorical_accuracy: 0.9660 - f1_m: 0.9662\n",
            "Epoch 17: val_categorical_accuracy did not improve from 0.99172\n",
            "241/241 [==============================] - 72s 299ms/step - loss: 0.1300 - categorical_accuracy: 0.9660 - f1_m: 0.9662 - val_loss: 0.0678 - val_categorical_accuracy: 0.9807 - val_f1_m: 0.9793\n",
            "Epoch 18/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1240 - categorical_accuracy: 0.9673 - f1_m: 0.9674\n",
            "Epoch 18: val_categorical_accuracy did not improve from 0.99172\n",
            "241/241 [==============================] - 74s 307ms/step - loss: 0.1240 - categorical_accuracy: 0.9673 - f1_m: 0.9674 - val_loss: 0.0864 - val_categorical_accuracy: 0.9793 - val_f1_m: 0.9766\n",
            "Epoch 19/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1274 - categorical_accuracy: 0.9690 - f1_m: 0.9694\n",
            "Epoch 19: val_categorical_accuracy did not improve from 0.99172\n",
            "241/241 [==============================] - 72s 299ms/step - loss: 0.1274 - categorical_accuracy: 0.9690 - f1_m: 0.9694 - val_loss: 0.0407 - val_categorical_accuracy: 0.9917 - val_f1_m: 0.9917\n",
            "Epoch 20/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0529 - categorical_accuracy: 0.9875 - f1_m: 0.9876\n",
            "Epoch 20: val_categorical_accuracy did not improve from 0.99172\n",
            "241/241 [==============================] - 72s 298ms/step - loss: 0.0529 - categorical_accuracy: 0.9875 - f1_m: 0.9876 - val_loss: 0.0989 - val_categorical_accuracy: 0.9738 - val_f1_m: 0.9724\n",
            "Epoch 21/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0967 - categorical_accuracy: 0.9762 - f1_m: 0.9765\n",
            "Epoch 21: val_categorical_accuracy did not improve from 0.99172\n",
            "241/241 [==============================] - 72s 301ms/step - loss: 0.0967 - categorical_accuracy: 0.9762 - f1_m: 0.9765 - val_loss: 0.1406 - val_categorical_accuracy: 0.9586 - val_f1_m: 0.9559\n",
            "Epoch 22/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1152 - categorical_accuracy: 0.9720 - f1_m: 0.9719\n",
            "Epoch 22: val_categorical_accuracy did not improve from 0.99172\n",
            "241/241 [==============================] - 73s 305ms/step - loss: 0.1152 - categorical_accuracy: 0.9720 - f1_m: 0.9719 - val_loss: 0.0777 - val_categorical_accuracy: 0.9834 - val_f1_m: 0.9807\n",
            "Epoch 23/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0699 - categorical_accuracy: 0.9845 - f1_m: 0.9842\n",
            "Epoch 23: val_categorical_accuracy improved from 0.99172 to 0.99310, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 76s 314ms/step - loss: 0.0699 - categorical_accuracy: 0.9845 - f1_m: 0.9842 - val_loss: 0.0246 - val_categorical_accuracy: 0.9931 - val_f1_m: 0.9931\n",
            "Epoch 24/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0584 - categorical_accuracy: 0.9864 - f1_m: 0.9861\n",
            "Epoch 24: val_categorical_accuracy did not improve from 0.99310\n",
            "241/241 [==============================] - 72s 300ms/step - loss: 0.0584 - categorical_accuracy: 0.9864 - f1_m: 0.9861 - val_loss: 0.0496 - val_categorical_accuracy: 0.9876 - val_f1_m: 0.9876\n",
            "Epoch 25/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0758 - categorical_accuracy: 0.9826 - f1_m: 0.9830\n",
            "Epoch 25: val_categorical_accuracy did not improve from 0.99310\n",
            "241/241 [==============================] - 73s 303ms/step - loss: 0.0758 - categorical_accuracy: 0.9826 - f1_m: 0.9830 - val_loss: 0.1440 - val_categorical_accuracy: 0.9710 - val_f1_m: 0.9655\n",
            "Epoch 26/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.1042 - categorical_accuracy: 0.9748 - f1_m: 0.9747\n",
            "Epoch 26: val_categorical_accuracy did not improve from 0.99310\n",
            "241/241 [==============================] - 72s 300ms/step - loss: 0.1042 - categorical_accuracy: 0.9748 - f1_m: 0.9747 - val_loss: 0.0551 - val_categorical_accuracy: 0.9848 - val_f1_m: 0.9834\n",
            "Epoch 27/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0595 - categorical_accuracy: 0.9856 - f1_m: 0.9855\n",
            "Epoch 27: val_categorical_accuracy did not improve from 0.99310\n",
            "241/241 [==============================] - 75s 311ms/step - loss: 0.0595 - categorical_accuracy: 0.9856 - f1_m: 0.9855 - val_loss: 0.0691 - val_categorical_accuracy: 0.9807 - val_f1_m: 0.9807\n",
            "Epoch 28/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0669 - categorical_accuracy: 0.9815 - f1_m: 0.9817\n",
            "Epoch 28: val_categorical_accuracy did not improve from 0.99310\n",
            "241/241 [==============================] - 72s 300ms/step - loss: 0.0669 - categorical_accuracy: 0.9815 - f1_m: 0.9817 - val_loss: 0.0558 - val_categorical_accuracy: 0.9834 - val_f1_m: 0.9834\n",
            "Epoch 29/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0903 - categorical_accuracy: 0.9787 - f1_m: 0.9775\n",
            "Epoch 29: val_categorical_accuracy did not improve from 0.99310\n",
            "241/241 [==============================] - 72s 299ms/step - loss: 0.0903 - categorical_accuracy: 0.9787 - f1_m: 0.9775 - val_loss: 0.0498 - val_categorical_accuracy: 0.9890 - val_f1_m: 0.9876\n",
            "Epoch 30/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0630 - categorical_accuracy: 0.9853 - f1_m: 0.9854\n",
            "Epoch 30: val_categorical_accuracy did not improve from 0.99310\n",
            "241/241 [==============================] - 72s 299ms/step - loss: 0.0630 - categorical_accuracy: 0.9853 - f1_m: 0.9854 - val_loss: 0.0526 - val_categorical_accuracy: 0.9876 - val_f1_m: 0.9876\n",
            "Epoch 31/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0805 - categorical_accuracy: 0.9795 - f1_m: 0.9796\n",
            "Epoch 31: val_categorical_accuracy did not improve from 0.99310\n",
            "241/241 [==============================] - 77s 317ms/step - loss: 0.0805 - categorical_accuracy: 0.9795 - f1_m: 0.9796 - val_loss: 0.0535 - val_categorical_accuracy: 0.9862 - val_f1_m: 0.9862\n",
            "Epoch 32/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0928 - categorical_accuracy: 0.9756 - f1_m: 0.9754\n",
            "Epoch 32: val_categorical_accuracy did not improve from 0.99310\n",
            "241/241 [==============================] - 75s 312ms/step - loss: 0.0928 - categorical_accuracy: 0.9756 - f1_m: 0.9754 - val_loss: 0.0576 - val_categorical_accuracy: 0.9862 - val_f1_m: 0.9848\n",
            "Epoch 33/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0383 - categorical_accuracy: 0.9914 - f1_m: 0.9911\n",
            "Epoch 33: val_categorical_accuracy improved from 0.99310 to 0.99448, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 74s 307ms/step - loss: 0.0383 - categorical_accuracy: 0.9914 - f1_m: 0.9911 - val_loss: 0.0211 - val_categorical_accuracy: 0.9945 - val_f1_m: 0.9931\n",
            "Epoch 34/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0631 - categorical_accuracy: 0.9834 - f1_m: 0.9831\n",
            "Epoch 34: val_categorical_accuracy did not improve from 0.99448\n",
            "241/241 [==============================] - 74s 305ms/step - loss: 0.0631 - categorical_accuracy: 0.9834 - f1_m: 0.9831 - val_loss: 0.0818 - val_categorical_accuracy: 0.9793 - val_f1_m: 0.9752\n",
            "Epoch 35/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0683 - categorical_accuracy: 0.9812 - f1_m: 0.9813\n",
            "Epoch 35: val_categorical_accuracy did not improve from 0.99448\n",
            "241/241 [==============================] - 75s 309ms/step - loss: 0.0683 - categorical_accuracy: 0.9812 - f1_m: 0.9813 - val_loss: 0.0201 - val_categorical_accuracy: 0.9945 - val_f1_m: 0.9945\n",
            "Epoch 36/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0323 - categorical_accuracy: 0.9925 - f1_m: 0.9930\n",
            "Epoch 36: val_categorical_accuracy did not improve from 0.99448\n",
            "241/241 [==============================] - 72s 299ms/step - loss: 0.0323 - categorical_accuracy: 0.9925 - f1_m: 0.9930 - val_loss: 0.1207 - val_categorical_accuracy: 0.9683 - val_f1_m: 0.9669\n",
            "Epoch 37/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0343 - categorical_accuracy: 0.9925 - f1_m: 0.9925\n",
            "Epoch 37: val_categorical_accuracy did not improve from 0.99448\n",
            "241/241 [==============================] - 73s 303ms/step - loss: 0.0343 - categorical_accuracy: 0.9925 - f1_m: 0.9925 - val_loss: 0.0552 - val_categorical_accuracy: 0.9848 - val_f1_m: 0.9848\n",
            "Epoch 38/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0522 - categorical_accuracy: 0.9870 - f1_m: 0.9871\n",
            "Epoch 38: val_categorical_accuracy did not improve from 0.99448\n",
            "241/241 [==============================] - 74s 306ms/step - loss: 0.0522 - categorical_accuracy: 0.9870 - f1_m: 0.9871 - val_loss: 0.1345 - val_categorical_accuracy: 0.9697 - val_f1_m: 0.9683\n",
            "Epoch 39/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0875 - categorical_accuracy: 0.9792 - f1_m: 0.9799\n",
            "Epoch 39: val_categorical_accuracy did not improve from 0.99448\n",
            "241/241 [==============================] - 72s 300ms/step - loss: 0.0875 - categorical_accuracy: 0.9792 - f1_m: 0.9799 - val_loss: 0.0414 - val_categorical_accuracy: 0.9903 - val_f1_m: 0.9890\n",
            "Epoch 40/40\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.0131 - categorical_accuracy: 0.9967 - f1_m: 0.9968\n",
            "Epoch 40: val_categorical_accuracy improved from 0.99448 to 0.99862, saving model to /content/drive/MyDrive/Audiodata/grayTT_wts.hdf5\n",
            "241/241 [==============================] - 77s 319ms/step - loss: 0.0131 - categorical_accuracy: 0.9967 - f1_m: 0.9968 - val_loss: 0.0049 - val_categorical_accuracy: 0.9986 - val_f1_m: 0.9986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-c745ba16ed14>:98: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  y_pred = model.predict_generator(test_generator, STEP_SIZE_TEST, verbose=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "906/906 [==============================] - 24s 24ms/step\n",
            "(906,)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.86      0.88       146\n",
            "           1       0.83      0.87      0.85       116\n",
            "           2       0.76      0.90      0.82       130\n",
            "           3       0.83      0.81      0.82       138\n",
            "           4       0.87      0.90      0.88       137\n",
            "           5       0.87      0.76      0.81       130\n",
            "           6       0.92      0.83      0.87       109\n",
            "\n",
            "    accuracy                           0.85       906\n",
            "   macro avg       0.85      0.85      0.85       906\n",
            "weighted avg       0.85      0.85      0.85       906\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAGiCAYAAAB6c8WBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAv70lEQVR4nO3df3RU5Z3H8U8SMhMgEJBIEkIki7+ARRJMyBgQcTU1qx4UT1sjapNGpSsFVp1qJasmglsGq9JYQVAUdfWwoC5af0bpVOxhiaYmshUFLKJGkQRSNWCUiczM/tGzs52bABmY4SbzvF/n3HPKzZ3nfq8V55Pv89x7E4LBYFAAAMBYiXYXAAAA7EUYAADAcIQBAAAMRxgAAMBwhAEAAAxHGAAAwHCEAQAADEcYAADAcIQBAAAMRxgAAMBwhAEAAHqRZcuWKTc3VykpKXK5XGpoaDjksd9//70WLlyok08+WSkpKcrLy1NdXV3E5yQMAADQS6xdu1Zut1s1NTVqampSXl6eSktLtWfPnm6Pv/322/XQQw/pgQce0AcffKDrr79el112md59992IzpvAi4oAAOgdXC6XJk2apKVLl0qSAoGAcnJyNG/ePM2fP7/L8SNGjNBtt92mOXPmhPb98Ic/VP/+/fXUU0/1+Lx0BgAAiCGfz6d9+/aFbT6fr8txnZ2damxsVElJSWhfYmKiSkpKVF9ff8ixU1JSwvb1799fGzdujKjGfhEdHUMDBw60u4SYamtrs7sERMHBgwftLiGmBg0aZHcJMef3++0uIeYSE+P/97yEhIQ+M35NTY0WLFjQZd+dd94Ztq+trU1+v18ZGRlh+zMyMrRt27Zuxy4tLdWSJUt0zjnn6OSTT5bX69W6desi/vc8/v+NAQAgQgkJCVHbqqqq1N7eHrZVVVVFpc77779fp556qsaMGSOHw6G5c+eqsrIy4kBIGAAAIIacTqcGDx4ctjmdzi7HpaenKykpSa2trWH7W1tblZmZ2e3YJ554op5//nl1dHTo008/1bZt25SamqrRo0dHVCNhAAAAi2h2BnrK4XCooKBAXq83tC8QCMjr9aq4uPiwn01JSVF2drYOHjyo//qv/9Kll14a0fX2mjUDAAD0FrFek3AobrdbFRUVKiwsVFFRkWpra9XR0aHKykpJUnl5ubKzs+XxeCRJb7/9tnbt2qX8/Hzt2rVLd955pwKBgH75y19GdF7CAAAAFnaFgbKyMu3du1fV1dVqaWlRfn6+6urqQosKm5ubw9YDHDhwQLfffrt27typ1NRUXXTRRXryySc1ZMiQiM7ba54zwN0E6Au4m6Dv426C+BDrL+vk5OSojfX9999HbaxYoTMAAICFXZ0BuxAGAACwMC0MxH8vCQAAHBadAQAALEzrDBAGAACwMC0MME0AAIDh6AwAAGBhWmeAMAAAgIVpYYBpAgAADEdnAAAAC9M6A4QBAAAsCAMAABjOtDDAmgEAAAxHZwAAAAvTOgOEAQAALEwLA0wTAABgODoDAABYmNYZiDgMtLW1adWqVaqvr1dLS4skKTMzU5MnT9ZPf/pTnXjiiVEvEgCA48m0MJAQDAaDPT34T3/6k0pLSzVgwACVlJQoIyNDktTa2iqv16tvv/1Wr732mgoLCw87js/nk8/nC9uXmZkZ1//w29ra7C4BUXDw4EG7S4ipQYMG2V1CzPn9frtLiLnExPifAY7198UJJ5wQtbG+/PLLqI0VKxGFgbPOOkt5eXlasWJFl/8jgsGgrr/+ev35z39WfX39Yce58847tWDBgrB9/fr1k8PhiKD0voUwEB8IA30fYSA+xDoMDBs2LGpj/fWvf43aWLESURjo37+/3n33XY0ZM6bbn2/btk0TJ07Ud999d9hx6AygryIM9H2EgfgQ6++L9PT0qI3VF/77H9GagczMTDU0NBwyDDQ0NISmDg7H6XTK6XSG7YvnIAAAQG8WURi4+eab9bOf/UyNjY06//zzu6wZWLlype69996YFAoAwPFi2i+oEYWBOXPmKD09Xb/5zW/04IMPhtptSUlJKigo0OOPP67LL788JoUCAHC8mBYGIloz8Pe+//770DxIenq6kpOTj6mQgQMHHtPne7u+MGeEI2PNQN/HmoH4EOsv655MefdUa2tr1MaKlaN+6FBycrKysrKiWQsAALABTyAEAMDCtGkCwgAAABamhYH4n1gCAACHRWcAAAALOgMAABguISEhalukli1bptzcXKWkpMjlcqmhoeGwx9fW1ur0009X//79lZOTo5tuukkHDhyI6JyEAQAAeom1a9fK7XarpqZGTU1NysvLU2lpqfbs2dPt8atXr9b8+fNVU1OjrVu36tFHH9XatWv1b//2bxGd96ifMxBtPGcAfQHPGej7eM5AfIh1G3/kyJFRG+vzzz/v8bEul0uTJk3S0qVLJUmBQEA5OTmaN2+e5s+f3+X4uXPnauvWrfJ6vaF9v/jFL/T2229r48aNPT5v/P8bAwBAhKI5TeDz+bRv376wzfqyPknq7OxUY2OjSkpKQvsSExNVUlJyyLcBT548WY2NjaGphJ07d+qVV17RRRddFNH1EgYAAIghj8ejtLS0sM3j8XQ5rq2tTX6/v8vTDzMyMtTS0tLt2FdeeaUWLlyos88+W8nJyTr55JN17rnnRjxNQBgAAMAimp2Bqqoqtbe3h21VVVVRqXPDhg1atGiRHnzwQTU1NWndunV6+eWXddddd0U0DrcWAgBgEc01CU6nU06n84jHpaenKykpqcu7DFpbW5WZmdntZ+644w795Cc/0XXXXSdJOuOMM9TR0aGf/exnuu2223q8foTOAAAAFnbcWuhwOFRQUBC2GDAQCMjr9aq4uLjbz3z77bddvvCTkpIkSZHcH0BnAACAXsLtdquiokKFhYUqKipSbW2tOjo6VFlZKUkqLy9XdnZ2aM3B9OnTtWTJEk2cOFEul0s7duzQHXfcoenTp4dCQU8QBgAAsLDrCYRlZWXau3evqqur1dLSovz8fNXV1YUWFTY3N4d1Am6//XYlJCTo9ttv165du3TiiSdq+vTp+tWvfhXReXnOwHHCcwbiA88Z6Pt4zkB8iPWX9ejRo6M21s6dO6M2VqzE/78xAADgsJgmAADAwrQXFREGAACwMC0MME0AAIDhek1noL293e4SYsqEhVnWB2XEo9TUVLtLiKl4XyBpChMWSfbrF9uvL9M6A70mDAAA0FuYFgaYJgAAwHB0BgAAsDCtM0AYAADAgjAAAIDhTAsDrBkAAMBwdAYAALAwrTNAGAAAwMK0MMA0AQAAhqMzAACAhWmdAcIAAAAWpoUBpgkAADAcnQEAACxM6wwQBgAAsDAtDDBNAACA4egMAABgYVpngDAAAIAFYQAAAMOZFgZYMwAAgOHoDAAAYGFaZ4AwAACAhWlhgGkCAAAMR2cAAAAL0zoDhAEAACxMCwNMEwAAYLioh4HPPvtM11xzzWGP8fl82rdvX9jm8/miXQoAAEclISEhalukli1bptzcXKWkpMjlcqmhoeGQx5577rndnvPiiy+O6JxRDwNffvmlnnjiicMe4/F4lJaWFrbdfffd0S4FAICjYlcYWLt2rdxut2pqatTU1KS8vDyVlpZqz5493R6/bt067d69O7Rt2bJFSUlJ+vGPfxzZ9QaDwWAkH3jhhRcO+/OdO3fqF7/4hfx+/yGP8fl8XToBSUlJcjqdkZTSpwwaNMjuEmKutbXV7hJiLjU11e4SYioQCNhdAtAj/frFdsnbWWedFbWx3nrrrR4f63K5NGnSJC1dulTS3/5O5uTkaN68eZo/f/4RP19bW6vq6mrt3r1bAwcO7PF5I/6nOWPGDCUkJOhwGeJIScjpdHb54j948GCkpQAAEBPRXEDY3S/A3X0PdnZ2qrGxUVVVVaF9iYmJKikpUX19fY/O9eijj+qKK66IKAhIRzFNkJWVpXXr1ikQCHS7NTU1RTokAAC9SjSnCbqbGvd4PF3O2dbWJr/fr4yMjLD9GRkZamlpOWLNDQ0N2rJli6677rqIrzfiMFBQUKDGxsZD/vxIXQMAAHq7aIaBqqoqtbe3h21//9t/tDz66KM644wzVFRUFPFnI54muOWWW9TR0XHIn59yyil64403Ii4EAIB41N2UQHfS09OVlJTUZf1Va2urMjMzD/vZjo4OrVmzRgsXLjyqGiPuDEydOlX//M//fMifDxw4UNOmTTuqYgAA6A3suJvA4XCooKBAXq83tC8QCMjr9aq4uPiwn33mmWfk8/l09dVXH9X18gRCAAAs7HoCodvtVkVFhQoLC1VUVKTa2lp1dHSosrJSklReXq7s7Owuaw4effRRzZgxQ8OGDTuq8xIGAADoJcrKyrR3715VV1erpaVF+fn5qqurCy0qbG5uVmJieFN/+/bt2rhxo15//fWjPm/EzxmIlXi/tZDnDMQHnjMA9A6xfs7AOeecE7Wx/vjHP0ZtrFihMwAAgAUvKgIAAEahMwAAgIVpnQHCAAAAFqaFAaYJAAAwHJ0BAAAsTOsMEAYAALAgDAAAYDjTwgBrBgAAMBydAQAALEzrDBAGAACwMC0MME0AAIDh6AwAAGBhWmeAMAAAgIVpYYBpAgAADEdnAAAAC9M6A4SB46S9vd3uEmLO6XTaXULM+Xw+u0uIqX794v8/CYFAwO4S0AeYFgaYJgAAwHDx/2sAAAARMq0zQBgAAMCCMAAAgOFMCwOsGQAAwHB0BgAAsDCtM0AYAADAwrQwwDQBAACGozMAAICFaZ0BwgAAABamhQGmCQAAMBydAQAALEzrDBAGAACwMC0MME0AAEAvsmzZMuXm5iolJUUul0sNDQ2HPf7rr7/WnDlzlJWVJafTqdNOO02vvPJKROekMwAAgIVdnYG1a9fK7XZrxYoVcrlcqq2tVWlpqbZv367hw4d3Ob6zs1M/+MEPNHz4cD377LPKzs7Wp59+qiFDhkR0XsIAAAAWdoWBJUuWaNasWaqsrJQkrVixQi+//LJWrVql+fPndzl+1apV+vLLL7Vp0yYlJydLknJzcyM+L9MEAABYJCQkRG3z+Xzat29f2Obz+bqcs7OzU42NjSopKQntS0xMVElJierr67ut84UXXlBxcbHmzJmjjIwMjR8/XosWLZLf74/oegkDAADEkMfjUVpaWtjm8Xi6HNfW1ia/36+MjIyw/RkZGWppael27J07d+rZZ5+V3+/XK6+8ojvuuEP33Xef/v3f/z2iGpkmAADAIprTBFVVVXK73WH7nE5nVMYOBAIaPny4Hn74YSUlJamgoEC7du3SPffco5qamh6PQxgAAMAimmHA6XT26Ms/PT1dSUlJam1tDdvf2tqqzMzMbj+TlZWl5ORkJSUlhfaNHTtWLS0t6uzslMPh6FGNTBMAANALOBwOFRQUyOv1hvYFAgF5vV4VFxd3+5kpU6Zox44dCgQCoX0ffvihsrKyehwEJMIAAABdRHMBYSTcbrdWrlypJ554Qlu3btXs2bPV0dERurugvLxcVVVVoeNnz56tL7/8UjfccIM+/PBDvfzyy1q0aJHmzJkT0XmZJgAAwMKuWwvLysq0d+9eVVdXq6WlRfn5+aqrqwstKmxublZi4v//Hp+Tk6PXXntNN910kyZMmKDs7GzdcMMNuvXWWyM6b0IwGAxG9UqO0sGDB+0uIab+voUTr6K1IKY36+52oHjSr1/8/35gwt9FE8T639Urr7wyamOtXr06amPFSvz/zQcAIEK8m+AIvvvuO23cuFEffPBBl58dOHBA//Ef/3HEMXr6AAYAAOxg15oBu0QUBj788EONHTtW55xzjs444wxNmzZNu3fvDv28vb09tMjhcLp7AMPdd98defUAAOCYRRQGbr31Vo0fP1579uzR9u3bNWjQIE2ZMkXNzc0RnbSqqkrt7e1hW6SLHQAAiBXTOgMRrRnYtGmTfv/73ys9PV3p6el68cUX9fOf/1xTp07VG2+8oYEDB/ZonO4ewBDvCwgBAH1HX/kSj5aIOgPfffdd2ArOhIQELV++XNOnT9e0adP04YcfRr1AAACONzoDhzFmzBi98847Gjt2bNj+pUuXSpIuueSS6FUGAACOi4g6A5dddpn+8z//s9ufLV26VDNnzlQveWwBAABHzbTOAA8dOk5MeNAJDx3q+3joEPqKWP+72pM743rqsccei9pYscK7CQAAMFz8/xoAAECE+kp7P1oIAwAAWJgWBpgmAADAcHQGAACwMK0zQBgAAMCCMAAAgOFMCwOsGQAAwHB0BgAAsDCtM0AYAADAwrQwwDQBAACGozMAAICFaZ0BwgAAABamhQGmCQAAMBydAQAALEzrDBAGAACwMC0MME0AAIDh6AwAAGBhWmeAMAAAgAVhwCZff/213SXE1JAhQ+wuIeb2799vdwkxl5uba3cJMfXJJ5/YXULMJSbG/+xoIBCwu4Q+z7QwEP9/KwAAwGERBgAAsEhISIjaFqlly5YpNzdXKSkpcrlcamhoOOSxjz/+eJfzpaSkRHxOwgAAABZ2hYG1a9fK7XarpqZGTU1NysvLU2lpqfbs2XPIzwwePFi7d+8ObZ9++mnE10sYAACgl1iyZIlmzZqlyspKjRs3TitWrNCAAQO0atWqQ34mISFBmZmZoS0jIyPi8xIGAACwiGZnwOfzad++fWGbz+frcs7Ozk41NjaqpKQktC8xMVElJSWqr68/ZK3ffPONRo0apZycHF166aV6//33I75ewgAAABbRDAMej0dpaWlhm8fj6XLOtrY2+f3+Lr/ZZ2RkqKWlpds6Tz/9dK1atUq/+93v9NRTTykQCGjy5Mn6/PPPI7reXnNrIQAA8aiqqkputztsn9PpjMrYxcXFKi4uDv158uTJGjt2rB566CHdddddPR6HMAAAgEU0nzPgdDp79OWfnp6upKQktba2hu1vbW1VZmZmj86VnJysiRMnaseOHRHVyDQBAAAWdtxN4HA4VFBQIK/XG9oXCATk9XrDfvs/HL/fr/fee09ZWVkRXS+dAQAAegm3262KigoVFhaqqKhItbW16ujoUGVlpSSpvLxc2dnZoTUHCxcu1FlnnaVTTjlFX3/9te655x59+umnuu666yI6L2EAAAALux5HXFZWpr1796q6ulotLS3Kz89XXV1daFFhc3Nz2CO1v/rqK82aNUstLS0aOnSoCgoKtGnTJo0bNy6i8yYEg8FgVK/kKLW1tdldQkyZ8G6CAwcO2F1CzJ122ml2lxBTvJsgPpjwbgKHwxHT8W+99daojXX33XdHbaxYoTMAAIAFLyoCAABGoTMAAICFaZ0BwgAAABamhQGmCQAAMBydAQAALEzrDBAGAACwMC0MME0AAIDh6AwAAGBhWmeAMAAAgIVpYYBpAgAADEdnAAAAC9M6A7aEAZ/PJ5/P12Wf0+m0oxwAAMKYFgYinibYunWrHnvsMW3btk2StG3bNs2ePVvXXHON/vCHP/RoDI/Ho7S0tLDt/vvvj7QUAABiIiEhIWpbXxBRZ6Curk6XXnqpUlNT9e233+q5555TeXm58vLyFAgEdMEFF+j111/Xeeedd9hxqqqq5Ha7w/bt378/8uoBAMAxi6gzsHDhQt1yyy3661//qscee0xXXnmlZs2apfXr18vr9eqWW27R4sWLjziO0+nU4MGDwzamCAAAvYVpnYGIwsD777+vn/70p5Kkyy+/XPv379ePfvSj0M+vuuoq/fnPf45qgQAAHG+EgSP4vwtLTExUSkqK0tLSQj8bNGiQ2tvbo1cdAACIuYjCQG5urv7yl7+E/lxfX6+TTjop9Ofm5mZlZWVFrzoAAGxgWmcgogWEs2fPlt/vD/15/PjxYT9/9dVXj7h4EACA3q6vfIlHS0Rh4Prrrz/szxctWnRMxQAAgOOPJxACAGBBZwAAAMOZFgZ4UREAAIajMwAAgIVpnQHCAAAAFoQBAAAMZ1oYYM0AAACGozMAAICFaZ0BwgAAABamhQGmCQAA6EWWLVum3NxcpaSkyOVyqaGhoUefW7NmjRISEjRjxoyIz0kYAADAwq4XFa1du1Zut1s1NTVqampSXl6eSktLtWfPnsN+7pNPPtHNN9+sqVOnHtX1EgYAALCwKwwsWbJEs2bNUmVlpcaNG6cVK1ZowIABWrVq1SE/4/f7ddVVV2nBggUaPXr0UV0vYQAAgBjy+Xzat29f2Obz+boc19nZqcbGRpWUlIT2JSYmqqSkRPX19Yccf+HChRo+fLiuvfbao66RMAAAgEU0OwMej0dpaWlhm8fj6XLOtrY2+f1+ZWRkhO3PyMhQS0tLt3Vu3LhRjz76qFauXHlM18vdBAAAWETzboKqqiq53e6wfU6n85jH3b9/v37yk59o5cqVSk9PP6axCAMAAMSQ0+ns0Zd/enq6kpKS1NraGra/tbVVmZmZXY7/6KOP9Mknn2j69OmhfYFAQJLUr18/bd++XSeffHKPamSaAAAACzsWEDocDhUUFMjr9Yb2BQIBeb1eFRcXdzl+zJgxeu+997R58+bQdskll+if/umftHnzZuXk5PT43HQGAACwsOuhQ263WxUVFSosLFRRUZFqa2vV0dGhyspKSVJ5ebmys7Pl8XiUkpKi8ePHh31+yJAhktRl/5EQBgAAsLArDJSVlWnv3r2qrq5WS0uL8vPzVVdXF1pU2NzcrMTE6Df1E4LBYDDqox6F/5vniFednZ12lxBzDofD7hJi7uDBg3aXEFPRWNTU23V0dNhdQswNGDDA7hL6vAceeCBqY82bNy9qY8UKnQEAACxMezcBYQAAAAvTwgB3EwAAYDg6AwAAWJjWGSAMAABgYVoYYJoAAADD0RkAAMDCtM4AYQAAAAvTwgDTBAAAGI7OAAAAFqZ1BggDAABYEAYAADCcaWGANQMAABiOzgAAABamdQYIAwAAWJgWBpgmAADAcHQGAACwMK0zQBgAAMDCtDDANAEAAIajMwAAgIVpnQHCAAAAFqaFAaYJAAAwXFQ6A8Fg0LgUBQCIX6Z9p0WlM+B0OrV169ZoDAUAgO0SEhKitvUFEXUG3G53t/v9fr8WL16sYcOGSZKWLFly2HF8Pp98Pl/YvuTkZDmdzkjKAQAgJvrKl3i0RBQGamtrlZeXpyFDhoTtDwaD2rp1qwYOHNijf4Aej0cLFiwI21ddXa2amppIygEAAFGQEAwGgz09ePHixXr44Yf1yCOP6LzzzgvtT05O1v/8z/9o3LhxPRrHxM5AZ2en3SXEnMPhsLuEmDt48KDdJcRUPP8d/D8dHR12lxBzAwYMsLuEPm/16tVRG+vKK6+M2lixElFnYP78+Tr//PN19dVXa/r06fJ4PEpOTo74pE6ns8t/dAKBQMTjAAAQC6ZNE0S8gHDSpElqbGzU3r17VVhYqC1bthj3Dw0AgHhyVLcWpqam6oknntCaNWtUUlIiv98f7boAALCNab/kHtOthVdccYXeeecdrVu3TqNGjYpWTQAA2MrOWwuXLVum3NxcpaSkyOVyqaGh4ZDHrlu3ToWFhRoyZIgGDhyo/Px8PfnkkxGf85gfOjRy5EiNHDnyWIcBAMB4a9euldvt1ooVK+RyuVRbW6vS0lJt375dw4cP73L8CSecoNtuu01jxoyRw+HQSy+9pMrKSg0fPlylpaU9Pm9EdxPEUrwvIORugvjA3QR9H3cToCeefvrpqI11+eWX9/hYl8ulSZMmaenSpZL+9t2Yk5OjefPmaf78+T0a48wzz9TFF1+su+66q8fn5d0EAABYRHOawOfzad++fWGb9fZ66W+/NDY2NqqkpCS0LzExUSUlJaqvrz9izcFgUF6vV9u3b9c555wT0fUSBgAAiCGPx6O0tLSwzePxdDmura1Nfr9fGRkZYfszMjLU0tJyyPHb29uVmpoqh8Ohiy++WA888IB+8IMfRFQjrzAGAMAimncTVFVVdXmcfzSn5AYNGqTNmzfrm2++kdfrldvt1ujRo3Xuuef2eAzCAAAAFtEMA909aK876enpSkpKUmtra9j+1tZWZWZmHvJziYmJOuWUUyRJ+fn52rp1qzweT0RhgGkCAAAs7Li10OFwqKCgQF6vN7QvEAjI6/WquLi4x+MEAoFu1yQcDp0BAAB6CbfbrYqKChUWFqqoqEi1tbXq6OhQZWWlJKm8vFzZ2dmhNQcej0eFhYU6+eST5fP59Morr+jJJ5/U8uXLIzovYQAAAAu7nkBYVlamvXv3qrq6Wi0tLcrPz1ddXV1oUWFzc7MSE/+/qd/R0aGf//zn+vzzz9W/f3+NGTNGTz31lMrKyiI6L88ZOE54zkB84DkDfR/PGUBPPP/881Eba8aMGVEbK1ZYMwAAgOGYJgAAwMK0FxURBgAAsDAtDDBNAACA4egMAABgYVpngDAAAICFaWGAaQIAAAxHZwAAAAvTOgOEAQAALAgDAAAYzrQwwJoBAAAM12s6A3//4oV4FOnrJPui/fv3211CzKWlpdldQkzt3r3b7hJi7swzz7S7hJjbtm2b3SX0eaZ1BnpNGAAAoLcwLQzE96/jAADgiOgMAABgYVpngDAAAICFaWGAaQIAAAxHZwAAAAvTOgOEAQAALEwLA0wTAABgODoDAABYmNYZIAwAAGBBGAAAwHCmhQHWDAAAYDg6AwAAWJjWGSAMAABgYVoYYJoAAADD0RkAAMDCtM4AYQAAAAvTwgDTBAAAGI4wAACARUJCQtS2SC1btky5ublKSUmRy+VSQ0PDIY9duXKlpk6dqqFDh2ro0KEqKSk57PGHQhgAAMDCrjCwdu1aud1u1dTUqKmpSXl5eSotLdWePXu6PX7Dhg2aOXOm3njjDdXX1ysnJ0cXXHCBdu3aFdn1BoPBYESfwFFpb2+3u4SY6+zstLuEmEtLS7O7hJj68ssv7S4h5s4991y7S4i5bdu22V1Cn7dp06aojTV58uQeH+tyuTRp0iQtXbpUkhQIBJSTk6N58+Zp/vz5R/y83+/X0KFDtXTpUpWXl/f4vCwgBADAIpoLCH0+n3w+X9g+p9Mpp9MZtq+zs1ONjY2qqqoK7UtMTFRJSYnq6+t7dK5vv/1W33//vU444YSIamSaAAAAi2hOE3g8HqWlpYVtHo+nyznb2trk9/uVkZERtj8jI0MtLS09qvvWW2/ViBEjVFJSEtH10hkAAMAimp2Bqqoqud3usH3WrkA0LF68WGvWrNGGDRuUkpIS0WePKQx0dHTo6aef1o4dO5SVlaWZM2dq2LBhR/xcT1smAAD0dT39fktPT1dSUpJaW1vD9re2tiozM/Own7333nu1ePFi/f73v9eECRMirjGiaYJx48aFFhh99tlnGj9+vG666SatX79eNTU1GjdunD7++OMjjtPTlgkAAHaw424Ch8OhgoICeb3e0L5AICCv16vi4uJDfu7Xv/617rrrLtXV1amwsPCorjeizsC2bdt08OBBSX9re4wYMUKbN29WWlqavvnmG1122WW67bbbtHr16sOOc7xaJgAAHA27nkDodrtVUVGhwsJCFRUVqba2Vh0dHaqsrJQklZeXKzs7O/QL9N13363q6mqtXr1aubm5obUFqampSk1N7fF5j3qaoL6+XitWrAjdapWamqoFCxboiiuuOOJnmRIAAKCrsrIy7d27V9XV1WppaVF+fr7q6upCiwqbm5uVmPj/Tf3ly5ers7NTP/rRj8LGqamp0Z133tnj80YcBv4vLR04cEBZWVlhP8vOztbevXsjHRIAgF7FzncTzJ07V3Pnzu32Zxs2bAj78yeffBKVc0YcBs4//3z169dP+/bt0/bt2zV+/PjQzz799NMeLSAEAKA3M+1FRRGFgZqamrA/W+cjXnzxRU2dOvXYqwIAAMfNMYUBq3vuueeYigEAoDegMwAAgOFMCwM8jhgAAMPRGQAAwMK0zgBhAAAAC8IAAACGMy0MsGYAAADD0RkAAMDCtM4AYQAAAAvTwgDTBAAAGI7OAAAAFqZ1BggDAABYmBYGmCYAAMBwdAYAALAwrTNAGAAAwMK0MMA0AQAAhqMzAACAhWmdAcIAAAAWhAEAAAxnWhhgzQAAAIbrNZ2BQCBgdwkxlZaWZncJMdfa2mp3CTH33Xff2V1CTA0fPtzuEmLuvffes7uEmDPh/8c9e/bEdHzTOgO9JgwAANBbmBYGmCYAAMBwdAYAALAwrTNAGAAAwMK0MMA0AQAAhqMzAACAhWmdAcIAAAAWpoUBpgkAADAcYQAAAIuEhISobZFatmyZcnNzlZKSIpfLpYaGhkMe+/777+uHP/yhcnNzlZCQoNra2qO6XsIAAAAWdoWBtWvXyu12q6amRk1NTcrLy1Npaekhn7j47bffavTo0Vq8eLEyMzOP/nqDwWDwqD8dRfH+OOLExPjPXSY8jjglJcXuEmJq0KBBdpcQc36/3+4SYi47O9vuEmIu1o8j/vzzz6M21oknniifzxe2z+l0yul0djnW5XJp0qRJWrp0qaS/fTfm5ORo3rx5mj9//mHPk5ubqxtvvFE33nhjxDXG/zcUAAA28ng8SktLC9s8Hk+X4zo7O9XY2KiSkpLQvsTERJWUlKi+vj6mNXI3AQAAFtG8m6CqqkputztsX3ddgba2Nvn9fmVkZITtz8jI0LZt26JWT3cIAwAAWEQzDBxqSqA3YZoAAIBeID09XUlJSV3WX7W2th7T4sCeIAwAAGBhx90EDodDBQUF8nq9oX2BQEBer1fFxcWxuMwQpgkAALCw6wmEbrdbFRUVKiwsVFFRkWpra9XR0aHKykpJUnl5ubKzs0MLEDs7O/XBBx+E/veuXbu0efNmpaam6pRTTunxeQkDAAD0EmVlZdq7d6+qq6vV0tKi/Px81dXVhRYVNjc3h92q/sUXX2jixImhP99777269957NW3aNG3YsKHH5+U5A8cJzxmIDzxnoO/jOQPxIdbPGYjmf8+sdwf0RnQGAACw4EVFAADAKHQGAACwMK0zQBgAAMCCMAAAgOFMCwOsGQAAwHARhYGmpiZ9/PHHoT8/+eSTmjJlinJycnT22WdrzZo1PRrH5/Np3759YZv19Y4AANjFjicQ2imiMFBZWamPPvpIkvTII4/oX/7lX1RYWKjbbrtNkyZN0qxZs7Rq1aojjtPd6xwXL158dFcAAECUmRYGInro0IABA7R161aNGjVKZ555pmbPnq1Zs2aFfr569Wr96le/0vvvv3/YcXw+X5dOQHJycq9/q9Ox4KFD8YGHDvV9PHQoPsT6oUNfffVV1MYaOnRo1MaKlYgWEA4YMEBtbW0aNWqUdu3apaKiorCfu1yusGmEQ+nudY7x/gRCAEDf0Vd+o4+WiH5dvfDCC7V8+XJJ0rRp0/Tss8+G/fzpp5+O6MUIAAD0RqZNE0TUGbj77rs1ZcoUTZs2TYWFhbrvvvu0YcMGjR07Vtu3b9dbb72l5557Lla1AgCAGIioMzBixAi9++67Ki4uVl1dnYLBoBoaGvT6669r5MiR+u///m9ddNFFsaoVAIDjwrTOAG8tPE5YQBgfWEDY97GAMD7EegHh/v37ozZWX/h7Ff/fUAAA4LB4HDEAABZ9pb0fLYQBAAAsCAMAABjOtDDAmgEAAAxHZwAAAAvTOgOEAQAALEwLA0wTAABgODoDAABYmNYZIAwAAGBhWhhgmgAAAMPRGQAAwMK0zgBhAAAAC9PCANMEAAAYjs4AAAAWpnUGCAMAAFiYFgaYJgAAwCIhISFqW6SWLVum3NxcpaSkyOVyqaGh4bDHP/PMMxozZoxSUlJ0xhln6JVXXon4nIQBAAB6ibVr18rtdqumpkZNTU3Ky8tTaWmp9uzZ0+3xmzZt0syZM3Xttdfq3Xff1YwZMzRjxgxt2bIlovMmBIPBYDQu4FgFAgG7S4ipxMT4z12tra12lxBzKSkpdpcQU4MGDbK7hJjz+/12lxBz2dnZdpcQc4f6cuyNfD6ffD5f2D6n0ymn09nlWJfLpUmTJmnp0qWS/vbdmJOTo3nz5mn+/Pldji8rK1NHR4deeuml0L6zzjpL+fn5WrFiRc+LDBrowIEDwZqamuCBAwfsLiVm4v0a4/36gkGuMR7E+/UFg2Zc47GqqakJSgrbampquhzn8/mCSUlJweeeey5sf3l5efCSSy7pduycnJzgb37zm7B91dXVwQkTJkRUY6/pDBxP+/btU1pamtrb2zV48GC7y4mJeL/GeL8+iWuMB/F+fZIZ13isetoZ+OKLL5Sdna1NmzapuLg4tP+Xv/yl3nzzTb399ttdxnY4HHriiSc0c+bM0L4HH3xQCxYsiKhby90EAADE0KGmBHqT+J/IBgCgD0hPT1dSUlKX3+hbW1uVmZnZ7WcyMzMjOv5QCAMAAPQCDodDBQUF8nq9oX2BQEBerzds2uDvFRcXhx0vSevXrz/k8Ydi5DSB0+lUTU1Nr2/bHIt4v8Z4vz6Ja4wH8X59khnXeDy53W5VVFSosLBQRUVFqq2tVUdHhyorKyVJ5eXlys7OlsfjkSTdcMMNmjZtmu677z5dfPHFWrNmjd555x09/PDDEZ3XyAWEAAD0VkuXLtU999yjlpYW5efn67e//a1cLpck6dxzz1Vubq4ef/zx0PHPPPOMbr/9dn3yySc69dRT9etf/1oXXXRRROckDAAAYDjWDAAAYDjCAAAAhiMMAABgOMIAAACGMzIMRPp6yL7kj3/8o6ZPn64RI0YoISFBzz//vN0lRZXH49GkSZM0aNAgDR8+XDNmzND27dvtLiuqli9frgkTJmjw4MEaPHiwiouL9eqrr9pdVswsXrxYCQkJuvHGG+0uJWruvPPOLq+xHTNmjN1lRd2uXbt09dVXa9iwYerfv7/OOOMMvfPOO3aXhaNgXBiI9PWQfU1HR4fy8vK0bNkyu0uJiTfffFNz5szRW2+9pfXr1+v777/XBRdcoI6ODrtLi5qRI0dq8eLFamxs1DvvvKPzzjtPl156qd5//327S4u6P/3pT3rooYc0YcIEu0uJun/8x3/U7t27Q9vGjRvtLimqvvrqK02ZMkXJycl69dVX9cEHH+i+++7T0KFD7S4NRyOi1xrFgaKiouCcOXNCf/b7/cERI0YEPR6PjVXFhqQub7+KN3v27AlKCr755pt2lxJTQ4cODT7yyCN2lxFV+/fvD5566qnB9evXB6dNmxa84YYb7C4pampqaoJ5eXl2lxFTt956a/Dss8+2uwxEiVGdgc7OTjU2NqqkpCS0LzExUSUlJaqvr7exMhyt9vZ2SdIJJ5xgcyWx4ff7tWbNGnV0dET8eNHebs6cObr44ovD/j7Gk7/85S8aMWKERo8erauuukrNzc12lxRVL7zwggoLC/XjH/9Yw4cP18SJE7Vy5Uq7y8JRMioMtLW1ye/3KyMjI2x/RkaGWlpabKoKRysQCOjGG2/UlClTNH78eLvLiar33ntPqampcjqduv766/Xcc89p3LhxdpcVNWvWrFFTU1PokarxxuVy6fHHH1ddXZ2WL1+ujz/+WFOnTtX+/fvtLi1qdu7cqeXLl+vUU0/Va6+9ptmzZ+tf//Vf9cQTT9hdGo6Cke8mQHyYM2eOtmzZEndzsZJ0+umna/PmzWpvb9ezzz6riooKvfnmm3ERCD777DPdcMMNWr9+vVJSUuwuJyYuvPDC0P+eMGGCXC6XRo0apaefflrXXnutjZVFTyAQUGFhoRYtWiRJmjhxorZs2aIVK1aooqLC5uoQKaM6A0fzekj0TnPnztVLL72kN954QyNHjrS7nKhzOBw65ZRTVFBQII/Ho7y8PN1///12lxUVjY2N2rNnj84880z169dP/fr105tvvqnf/va36tevn/x+v90lRt2QIUN02mmnaceOHXaXEjVZWVldwunYsWPjbjrEFEaFgaN5PSR6l2AwqLlz5+q5557TH/7wB/3DP/yD3SUdF4FAQD6fz+4youL888/Xe++9p82bN4e2wsJCXXXVVdq8ebOSkpLsLjHqvvnmG3300UfKysqyu5SomTJlSpfbej/88EONGjXKpopwLIybJjjS6yH7um+++Sbst4+PP/5Ymzdv1gknnKCTTjrJxsqiY86cOVq9erV+97vfadCgQaG1Hmlpaerfv7/N1UVHVVWVLrzwQp100knav3+/Vq9erQ0bNui1116zu7SoGDRoUJc1HgMHDtSwYcPiZu3HzTffrOnTp2vUqFH64osvVFNTo6SkJM2cOdPu0qLmpptu0uTJk7Vo0SJdfvnlamho0MMPPxzxq3PRS9h9O4MdHnjggeBJJ50UdDgcwaKiouBbb71ld0lR88YbbwQlddkqKirsLi0qurs2ScHHHnvM7tKi5pprrgmOGjUq6HA4gieeeGLw/PPPD77++ut2lxVT8XZrYVlZWTArKyvocDiC2dnZwbKysuCOHTvsLivqXnzxxeD48eODTqczOGbMmODDDz9sd0k4SrzCGAAAwxm1ZgAAAHRFGAAAwHCEAQAADEcYAADAcIQBAAAMRxgAAMBwhAEAAAxHGAAAwHCEAQAADEcYAADAcIQBAAAM979ZNZ6+HkZnOgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "epochs = 40\n",
        "i = 1\n",
        "df_metrics = pd.DataFrame()\n",
        "kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
        "for train_index, test_index in kf.split(df_large, id):\n",
        "    trainData = df_large.iloc[train_index]\n",
        "    testData = df_large.iloc[test_index]\n",
        "    print('Initializing Kfold %s'%str(i))\n",
        "    print('Train shape:',trainData.shape)\n",
        "    print('Test shape:',testData.shape)\n",
        "    \n",
        "\n",
        "    train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                       horizontal_flip = False, \n",
        "                                      vertical_flip = False, \n",
        "                                      #height_shift_range= 0.15, \n",
        "                                      width_shift_range=0.25,\n",
        "                                      #zoom_range=0.8,\n",
        "                                      zca_whitening=True,\n",
        "                                      fill_mode=\"reflect\",\n",
        "                                      #channel_shift_range=100,\n",
        "                                      validation_split=0.20)\n",
        "    test_datagen = ImageDataGenerator(rescale=1. / 255) \n",
        "\n",
        "    train_generator=train_datagen.flow_from_dataframe(\n",
        "                dataframe=trainData,\n",
        "                directory=\"./\",\n",
        "                x_col=\"id\",\n",
        "                y_col=\"label\",\n",
        "                batch_size=batch_size,\n",
        "                #color_mode=\"grayscale\",\n",
        "                shuffle=True,\n",
        "                class_mode=\"categorical\",\n",
        "                seed=42,\n",
        "                target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "\n",
        "    valid_generator=train_datagen.flow_from_dataframe(\n",
        "                dataframe=trainData,\n",
        "                directory=\"./\",\n",
        "                x_col=\"id\",\n",
        "                y_col=\"label\",\n",
        "                batch_size=1,\n",
        "                #color_mode=\"grayscale\",\n",
        "                shuffle=False,\n",
        "                class_mode=\"categorical\",\n",
        "                seed=42,\n",
        "                subset=\"validation\",\n",
        "                target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "        \n",
        "    test_generator=test_datagen.flow_from_dataframe(\n",
        "                dataframe=testData,\n",
        "                directory=\"./\",\n",
        "                x_col=\"id\",\n",
        "                y_col=\"label\",\n",
        "                #color_mode=\"grayscale\",\n",
        "                batch_size=1,\n",
        "                shuffle=False,\n",
        "                class_mode=\"categorical\",\n",
        "                target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "\n",
        "    STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "    STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
        "    STEP_SIZE_TEST=test_generator.n//test_generator.batch_size \n",
        "\n",
        "    #model = define_model()\n",
        "    #model.summary()\n",
        "    #model.load_weights('D:/emotion_audio/kfold/k_gray'+str(i)+'_wts.hdf5')\n",
        "    model = get_model()\n",
        "    model.summary()\n",
        "    total_steps = 3627*10\n",
        "    decay_steps = total_steps * 1.0\n",
        "\n",
        "    cosine_decay_scheduler = tf.keras.optimizers.schedules.CosineDecay(\n",
        "        1e-4, decay_steps, alpha=0.1\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=cosine_decay_scheduler),\n",
        "        loss=dice_crossentropy,\n",
        "        metrics=['categorical_accuracy', f1_m],\n",
        "    )\n",
        "\n",
        "    if i==1: \n",
        "      model.load_weights('/content/drive/MyDrive/Audiodata/grayTT_wts.hdf5')\n",
        "    else:\n",
        "      model.fit_generator(generator=train_generator,\n",
        "                steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                validation_data=valid_generator,\n",
        "                validation_steps=STEP_SIZE_VALID,\n",
        "                epochs=epochs, callbacks=callbacks, verbose = 1)\n",
        "\n",
        "\n",
        "    \n",
        "    mcp_save = ModelCheckpoint('/content/drive/MyDrive/Audiodata/grayTT_wts.hdf5', save_best_only=True, verbose=1, monitor='val_categorical_accuracy', mode='max') \n",
        "    callbacks = [mcp_save]#,\n",
        "    shutil.copy('/content/drive/MyDrive/Audiodata/grayTT_wts.hdf5','/content/drive/MyDrive/Audiodata/Rez_ViTTiny16/k_gray'+str(i)+'_wts.hdf5')\n",
        "    model.load_weights('/content/drive/MyDrive/Audiodata/grayTT_wts.hdf5')\n",
        "    y_pred = model.predict_generator(test_generator, STEP_SIZE_TEST, verbose=1)\n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "    print(y_pred.shape)\n",
        "    report = classification_report(test_generator.classes, y_pred, output_dict=True)\n",
        "    classification_report_csv(report,i)\n",
        "    print(classification_report(test_generator.classes, y_pred))\n",
        "\n",
        "    ax = sns.heatmap(confusion_matrix(test_generator.classes, y_pred,normalize='true'), annot=False, cmap=\"gist_yarg\")\n",
        "    plt.show(block=False)\n",
        "    ax.figure.savefig('/content/drive/MyDrive/Audiodata/Rez_ViTTiny16/confusion_matrix_n'+str(i)+'_.png')\n",
        "\n",
        "    plt.pause(3)\n",
        "    plt.close()    \n",
        "    \n",
        "    i+=1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1=pd.read_csv('/content/drive/MyDrive/Audiodata/Rez_ViTTiny16/k_classification_report_'+str(1)+'_.csv')\n",
        "df2=pd.read_csv('/content/drive/MyDrive/Audiodata/Rez_ViTTiny16/k_classification_report_'+str(2)+'_.csv')\n",
        "df3=pd.read_csv('/content/drive/MyDrive/Audiodata/Rez_ViTTiny16/k_classification_report_'+str(3)+'_.csv')\n",
        "df4=pd.read_csv('/content/drive/MyDrive/Audiodata/Rez_ViTTiny16/k_classification_report_'+str(4)+'_.csv')\n",
        "df5=pd.read_csv('/content/drive/MyDrive/Audiodata/Rez_ViTTiny16/k_classification_report_'+str(5)+'_.csv')\n",
        "mean5=np.dstack((df1.values,df2.values,df3.values,df4.values,df5.values)).mean(axis=2)\n",
        "std5=np.dstack((df1.values,df2.values,df3.values,df4.values,df5.values)).std(axis=2)\n",
        "print('mean=  \\n', 100*np.dstack((df1.values,df2.values,df3.values,df4.values,df5.values))[:,0:3].mean(axis=2).round(4))\n",
        "print('std= \\n' , 100*np.dstack((df1.values,df2.values,df3.values,df4.values,df5.values))[:,0:3].std(axis=2).round(4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBsGF28-Vc49",
        "outputId": "f500a93b-e10c-496a-f8df-2524141ca886"
      },
      "id": "MBsGF28-Vc49",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean=  \n",
            " [[88.37 84.55 86.39]\n",
            " [84.28 85.79 84.88]\n",
            " [80.32 82.48 81.2 ]\n",
            " [79.59 77.88 78.59]\n",
            " [88.05 87.99 87.97]\n",
            " [80.47 83.31 81.57]\n",
            " [88.67 86.36 87.38]\n",
            " [83.97 83.97 83.97]\n",
            " [84.25 84.05 84.  ]\n",
            " [84.32 83.97 83.99]]\n",
            "std= \n",
            " [[1.57 3.06 1.94]\n",
            " [2.37 5.09 1.64]\n",
            " [4.99 5.12 3.08]\n",
            " [4.48 4.23 2.83]\n",
            " [4.14 1.12 2.29]\n",
            " [6.46 4.41 2.68]\n",
            " [3.71 3.24 1.45]\n",
            " [1.64 1.64 1.64]\n",
            " [1.7  1.62 1.67]\n",
            " [1.67 1.64 1.66]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de7acd52-daa2-4366-95b6-25fc605c030e",
      "metadata": {
        "id": "de7acd52-daa2-4366-95b6-25fc605c030e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}