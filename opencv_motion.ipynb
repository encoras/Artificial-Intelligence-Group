{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "14Nb4H_nRcnqE37pmkoG6gPiyMjNH3E4v",
      "authorship_tag": "ABX9TyM22ElgnPsUgINi386UWUue",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/encoras/Artificial-Intelligence-Group/blob/master/opencv_motion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Approach to Moving Object Detection\n",
        "\n",
        "https://learnopencv.com/moving-object-detection-with-opencv/\n",
        "\n",
        "https://www.youtube.com/watch?v=O3b8lVF93jU\n",
        "\n",
        "\n",
        "https://www.youtube.com/watch?v=1gi5qn1khVk"
      ],
      "metadata": {
        "id": "60dttn802Fve"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "n56hl4ZZXaK2",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "#or\n",
        "#inputt = 'https://raw.githubusercontent.com/encoras/Introduction-to-OpenCV/master/Camera3.mp4'\n",
        "#capture = cv2.VideoCapture(inputt)\n",
        "\n",
        "inputt = '/content/drive/MyDrive/Colab Notebooks/Camera3.mp4'\n",
        "\n",
        "capture = cv2.VideoCapture(cv2.samples.findFileOrKeep(inputt))\n",
        "frame_width = int(capture.get(3))\n",
        "frame_height = int(capture.get(4))\n",
        "out = cv2.VideoWriter('DiFF_Background_Subtraction_Tutorial_frame_output.mp4',cv2.VideoWriter_fourcc(*'mp4v'),30, (frame_width,frame_height))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ret, frame1 = capture.read()\n",
        "if not ret:\n",
        "    print(\"Cannot read first frame\")\n",
        "    # exit or handle error\n",
        "\n",
        "gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
        "gray1 = cv2.GaussianBlur(gray1, (5, 5), 0)\n",
        "\n",
        "frame_count = 0\n",
        "\n",
        "while True:\n",
        "    ret, frame2 = capture.read()\n",
        "    if not ret:\n",
        "        print(\"End of video / camera error\")\n",
        "        break\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "    # Convert to grayscale\n",
        "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
        "    gray2 = cv2.GaussianBlur(gray2, (5, 5), 0)\n",
        "\n",
        "    # Frame differencing\n",
        "    diff = cv2.absdiff(gray1, gray2)\n",
        "\n",
        "    # Threshold + noise reduction\n",
        "    _, thresh = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)\n",
        "    thresh = cv2.dilate(thresh, None, iterations=2)          # fill small gaps\n",
        "\n",
        "    # Find moving objects\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Make a copy to draw on (clean original)\n",
        "    display_frame = frame2.copy()\n",
        "\n",
        "    for contour in contours:\n",
        "        if cv2.contourArea(contour) < 200:   # adjust this threshold\n",
        "            continue\n",
        "\n",
        "        (x, y, w, h) = cv2.boundingRect(contour)\n",
        "\n",
        "        # Option A: Draw green rectangle (most common for motion detection)\n",
        "        cv2.rectangle(display_frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "\n",
        "        # Option B: If you really want to \"white out\" the moving region\n",
        "        # cv2.rectangle(display_frame, (x, y), (x+w, y+h), (255, 255, 255), -1)\n",
        "\n",
        "        # Optional: add area text\n",
        "        # cv2.putText(display_frame, f\"{cv2.contourArea(contour):.0f}\",\n",
        "        #             (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)\n",
        "\n",
        "    if frame_count < 5:\n",
        "      cv2_imshow(display_frame)   # Colab\n",
        "      print(f\"Showing frame #{frame_count}\")\n",
        "    # cv2.imshow(\"Motion\", display_frame)   # normal python\n",
        "    out.write(display_frame)\n",
        "    gray1 = gray2\n",
        "\n",
        "\n",
        "capture.release()\n",
        "out.release()"
      ],
      "metadata": {
        "id": "Vid0T_Y0dt6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OpenCV tools\n"
      ],
      "metadata": {
        "id": "t9UEPb57gpnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reset camera frame pointer to 0\n",
        "capture = cv2.VideoCapture(cv2.samples.findFileOrKeep(inputt))\n",
        "frame_width = int(capture.get(3))\n",
        "frame_height = int(capture.get(4))\n",
        "\n",
        "algo = 'MOG2'\n",
        "\n",
        "if algo == 'MOG2':\n",
        "    backSub = cv2.createBackgroundSubtractorMOG2(history=50, varThreshold=16, detectShadows=False)\n",
        "    backSub.setShadowThreshold(0.5)\n",
        "    out = cv2.VideoWriter('MOG_Background_Subtraction_Tutorial_frame_output.mp4',cv2.VideoWriter_fourcc(*'mp4v'),30, (frame_width,frame_height))\n",
        "else:\n",
        "    backSub = cv2.createBackgroundSubtractorKNN()\n",
        "    out = cv2.VideoWriter('KNN_Background_Subtraction_Tutorial_frame_output.mp4',cv2.VideoWriter_fourcc(*'mp4v'),30, (frame_width,frame_height))\n",
        "\n"
      ],
      "metadata": {
        "id": "YaapGWRTgo_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_motion_mask(fg_mask, min_thresh=0, kernel=np.array((9,9), dtype=np.uint8)):\n",
        "    \"\"\" Obtains image mask\n",
        "        Inputs:\n",
        "            fg_mask - foreground mask\n",
        "            kernel - kernel for Morphological Operations\n",
        "        Outputs:\n",
        "            mask - Thresholded mask for moving pixels\n",
        "        \"\"\"\n",
        "    _, thresh = cv2.threshold(fg_mask,min_thresh,255,cv2.THRESH_BINARY)\n",
        "    motion_mask = cv2.medianBlur(thresh, 5)\n",
        "\n",
        "    # morphological operations\n",
        "    motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "    motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
        "\n",
        "    return motion_mask"
      ],
      "metadata": {
        "id": "CDir1z1hb3z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame_count = 0\n",
        "while True:\n",
        "    ret, frame = capture.read()\n",
        "    if not ret:\n",
        "        print(\"End of video\")\n",
        "        break\n",
        "    frame_count += 1\n",
        "    # Apply background subtractor\n",
        "    fgMask = backSub.apply(frame)\n",
        "\n",
        "    # Get cleaned motion mask\n",
        "    mask = get_motion_mask(fgMask)\n",
        "\n",
        "    # Find contours on the mask\n",
        "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Draw on COLOR copy of original frame (key fix: was drawing on grayscale mask before)\n",
        "    display_frame = frame.copy()  # Use frame.copy() instead of mask.copy()\n",
        "\n",
        "    for contour in contours:\n",
        "        if cv2.contourArea(contour) < 200:  # Adjust threshold as needed\n",
        "            continue\n",
        "\n",
        "        (x, y, w, h) = cv2.boundingRect(contour)\n",
        "\n",
        "        # Draw green rectangle on color frame\n",
        "        cv2.rectangle(display_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "        # Optional: White out the region (uncomment if wanted)\n",
        "        # cv2.rectangle(display_frame, (x, y), (x + w, y + h), (255, 255, 255), -1)\n",
        "\n",
        "        # Optional: Add contour area text\n",
        "        # cv2.putText(display_frame, f\"{cv2.contourArea(contour):.0f}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "\n",
        "    # Display the result\n",
        "    if frame_count < 5:\n",
        "      cv2_imshow(display_frame)   # Colab\n",
        "      print(f\"Showing frame #{frame_count}\")\n",
        "\n",
        "    out.write(display_frame)\n",
        "\n",
        "# Cleanup\n",
        "capture.release()\n",
        "out.release()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ICWrxrqab5j0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleaned rectangles\n"
      ],
      "metadata": {
        "id": "PZ9MMEXIBOpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reset camera frame pointer to 0\n",
        "capture = cv2.VideoCapture(cv2.samples.findFileOrKeep(inputt))\n",
        "frame_width = int(capture.get(3))\n",
        "frame_height = int(capture.get(4))\n",
        "\n",
        "algo = 'MOG2'\n",
        "\n",
        "if algo == 'MOG2':\n",
        "    backSub = cv2.createBackgroundSubtractorMOG2(history=50, varThreshold=16, detectShadows=False)\n",
        "    backSub.setShadowThreshold(0.5)\n",
        "    out = cv2.VideoWriter('c_MOG_Background_Subtraction_Tutorial_frame_output.mp4',cv2.VideoWriter_fourcc(*'mp4v'),30, (frame_width,frame_height))\n",
        "else:\n",
        "    backSub = cv2.createBackgroundSubtractorKNN()\n",
        "    out = cv2.VideoWriter('c_KNN_Background_Subtraction_Tutorial_frame_output.mp4',cv2.VideoWriter_fourcc(*'mp4v'),30, (frame_width,frame_height))\n"
      ],
      "metadata": {
        "id": "bQ_KoaPsBSoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_nested_boxes(boxes, iou_threshold=0.7):\n",
        "    \"\"\"\n",
        "    boxes: list of [x, y, w, h]\n",
        "    Returns: list of kept boxes (non-nested or outer ones)\n",
        "    \"\"\"\n",
        "    if not boxes:\n",
        "        return []\n",
        "\n",
        "    # Sort by area descending → bigger boxes first\n",
        "    indexed_boxes = sorted(enumerate(boxes), key=lambda ib: ib[1][2] * ib[1][3], reverse=True)\n",
        "    kept_indices = set()\n",
        "\n",
        "    for i, (idx, box_a) in enumerate(indexed_boxes):\n",
        "        keep = True\n",
        "        xa, ya, wa, ha = box_a\n",
        "        area_a = wa * ha\n",
        "\n",
        "        for j in range(i):  # only check against already processed (larger) boxes\n",
        "            _, box_b = indexed_boxes[j]\n",
        "            xb, yb, wb, hb = box_b\n",
        "\n",
        "            # intersection\n",
        "            xi = max(xa, xb)\n",
        "            yi = max(ya, yb)\n",
        "            wi = max(0, min(xa+wa, xb+wb) - xi)\n",
        "            hi = max(0, min(ya+ha, yb+hb) - yi)\n",
        "            inter = wi * hi\n",
        "\n",
        "            # IoU = inter / area_a  (we care if smaller is mostly inside bigger)\n",
        "            if inter / area_a > iou_threshold:\n",
        "                keep = False\n",
        "                break\n",
        "\n",
        "        if keep:\n",
        "            kept_indices.add(idx)\n",
        "\n",
        "    # Return original order or sorted — your choice\n",
        "    return [boxes[i] for i in sorted(kept_indices)]"
      ],
      "metadata": {
        "id": "lGmfB1TUFcvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame_count = 0\n",
        "while True:\n",
        "    ret, frame = capture.read()\n",
        "    if not ret:\n",
        "        print(\"End of video\")\n",
        "        break\n",
        "    frame_count += 1\n",
        "    # Apply background subtractor\n",
        "    fgMask = backSub.apply(frame)\n",
        "\n",
        "    # Get cleaned motion mask\n",
        "    mask = get_motion_mask(fgMask)\n",
        "\n",
        "    # Find contours on the mask\n",
        "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Draw on COLOR copy of original frame (key fix: was drawing on grayscale mask before)\n",
        "    display_frame = frame.copy()  # Use frame.copy() instead of mask.copy()\n",
        "\n",
        "    # Step 1: collect all bounding boxes as [x, y, w, h]\n",
        "    rectangles = []\n",
        "    for contour in contours:\n",
        "        if cv2.contourArea(contour) < 200:          # your area filter\n",
        "            continue\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        rectangles.append([x, y, w, h])\n",
        "\n",
        "    if rectangles:\n",
        "        rect_array = np.array(rectangles + rectangles, dtype=np.int32)  # duplicate!\n",
        "        grouped, weights = cv2.groupRectangles(rect_array, groupThreshold=1, eps=0.35)\n",
        "\n",
        "        if isinstance(grouped, np.ndarray) and len(grouped) > 0:\n",
        "            grouped_rects = grouped.tolist()\n",
        "        else:\n",
        "            grouped_rects = rectangles  # fallback\n",
        "    else:\n",
        "        grouped_rects = []\n",
        "\n",
        "    # Step 3: draw only the grouped (cleaned) rectangles\n",
        "    display_frame = frame.copy()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    for rect in grouped_rects:\n",
        "        x, y, w, h = rect\n",
        "        cv2.rectangle(display_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "    # Display the result\n",
        "    if frame_count < 5:\n",
        "      cv2_imshow(display_frame)   # Colab\n",
        "      print(f\"Showing frame #{frame_count}\")\n",
        "\n",
        "    out.write(display_frame)\n",
        "\n",
        "# Cleanup\n",
        "capture.release()\n",
        "out.release()"
      ],
      "metadata": {
        "id": "COkhCGr1BadC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}